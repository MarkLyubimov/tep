{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:7\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import pyreadr as py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torch.optim import Adam, RMSprop\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import datetime\n",
    "\n",
    "device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Train data downloading\n",
    "Data link  \n",
    "https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/6C3JR1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! unzip ../../data/raw/dataverse_files.zip -d ../../data/raw/dataverse_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading train data in .R format\n",
    "a1 = py.read_r(\"../../data/raw/dataverse_files/TEP_FaultFree_Training.RData\")\n",
    "a2 = py.read_r(\"../../data/raw/dataverse_files/TEP_Faulty_Training.RData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objects that are present in a1 : odict_keys(['fault_free_training'])\n",
      "Objects that are present in a2 : odict_keys(['faulty_training'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Objects that are present in a1 :\", a1.keys())\n",
    "print(\"Objects that are present in a2 :\", a2.keys())\n",
    "# print(\"Objects that are present in a3 :\", a3.keys())\n",
    "# print(\"Objects that are present in a4 :\", a4.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatinating the train and the test dataset\n",
    "\n",
    "raw_train = pd.concat([a1['fault_free_training'], a2['faulty_training']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5250000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.250.000, 10.080.000\n",
    "len(raw_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "        'xmeas_1', 'xmeas_2', 'xmeas_3', 'xmeas_4', 'xmeas_5', 'xmeas_6', 'xmeas_7', 'xmeas_8',\n",
    "        'xmeas_9', 'xmeas_10', 'xmeas_11', 'xmeas_12', 'xmeas_13', 'xmeas_14', 'xmeas_15', 'xmeas_16', \n",
    "        'xmeas_17', 'xmeas_18', 'xmeas_19', 'xmeas_20', 'xmeas_21', 'xmeas_22', 'xmeas_23', 'xmeas_24', \n",
    "        'xmeas_25', 'xmeas_26', 'xmeas_27', 'xmeas_28', 'xmeas_29', 'xmeas_30', 'xmeas_31', 'xmeas_32',\n",
    "        'xmeas_33', 'xmeas_34', 'xmeas_35', 'xmeas_36', 'xmeas_37', 'xmeas_38', 'xmeas_39', 'xmeas_40', \n",
    "        'xmeas_41', 'xmv_1', 'xmv_2', 'xmv_3', 'xmv_4', 'xmv_5', 'xmv_6', 'xmv_7', 'xmv_8', 'xmv_9', \n",
    "        'xmv_10', 'xmv_11'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train['index'] = raw_train['faultNumber'] * 500 + raw_train['simulationRun'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_idx = raw_train[['index', 'faultNumber']].drop_duplicates()\n",
    "\n",
    "X_train_idx, X_val_idx = train_test_split(simulation_idx['index'], \n",
    "                                          stratify=simulation_idx['faultNumber'],\n",
    "                                          test_size=0.2, \n",
    "                                          random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = raw_train[raw_train['index'].isin(X_train_idx)].drop('index', axis=1)\n",
    "X_val = raw_train[raw_train['index'].isin(X_val_idx)].drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[features])\n",
    "\n",
    "X_train[features] = scaler.transform(X_train[features])\n",
    "X_val[features] = scaler.transform(X_val[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(y_pred, target):\n",
    "    \n",
    "    y_pred = torch.softmax(y_pred, dim=1)\n",
    "    y_pred = torch.max(y_pred, dim=1)[1]  \n",
    "    \n",
    "    return torch.eq(y_pred, target).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAULT_START_TRAINVAL = 20\n",
    "FAULT_START_TEST = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniRNN(nn.Module) :\n",
    "    def __init__(self, RNN_TYPE, NUM_LAYERS, INPUT_SIZE, HIDDEN_SIZE, LINEAR_SIZE, OUTPUT_SIZE, BIDIRECTIONAL, DESCRIPTION):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rnn_type = RNN_TYPE\n",
    "        self.hidden_size = HIDDEN_SIZE\n",
    "        self.num_layers = NUM_LAYERS\n",
    "        self.input_size = INPUT_SIZE\n",
    "        self.linear_size = LINEAR_SIZE\n",
    "        self.output_size = OUTPUT_SIZE\n",
    "        self.bidirectional = BIDIRECTIONAL\n",
    "        self.description = DESCRIPTION\n",
    "        \n",
    "        rnn_cell = getattr(nn, RNN_TYPE)\n",
    "        \n",
    "        self.rnn = rnn_cell(\n",
    "                        input_size=self.input_size, \n",
    "                        hidden_size=self.hidden_size,\n",
    "                        num_layers=self.num_layers, \n",
    "                        bidirectional=self.bidirectional,\n",
    "                        batch_first=True,\n",
    "                        dropout=0.4\n",
    "                )    \n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "                        nn.Linear(in_features=self.hidden_size*(self.bidirectional+1), out_features=self.linear_size),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(p=0.4),\n",
    "                        nn.Linear(in_features=self.linear_size, out_features=self.output_size),\n",
    "                )\n",
    "    \n",
    "    def get_params(self):\n",
    "        \n",
    "        return {\n",
    "            \"RNN_TYPE\": self.rnn_type,\n",
    "            \"HIDDEN_SIZE\": self.hidden_size,\n",
    "            \"NUM_LAYERS\": self.num_layers,\n",
    "            \"INPUT_SIZE\": self.input_size,\n",
    "            \"LINEAR_SIZE\": self.linear_size,\n",
    "            \"OUTPUT_SIZE\": self.output_size,\n",
    "            \"BIDIRECTIONAL\": self.bidirectional,\n",
    "            \"DESCRIPTION\": self.description,\n",
    "            }\n",
    "            \n",
    "    def forward(self, x, x_length):\n",
    "        \n",
    "        x_packed = pack_padded_sequence(x, x_length, batch_first=True)\n",
    "        x_rnn_out, _ = self.rnn(x_packed)\n",
    "        x_unpacked, _ = pad_packed_sequence(x_rnn_out, batch_first=True)\n",
    "        \n",
    "        idx_last_hidden = (x_length - 1).view(-1, 1).expand(len(x_length), x_unpacked.size(2)).unsqueeze(1)\n",
    "        idx_last_hidden = idx_last_hidden.to(x.device)\n",
    "        x_last_hiddens = x_unpacked.gather(1, idx_last_hidden).squeeze(1)\n",
    "        \n",
    "        x = self.head(x_last_hiddens)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModel(torch.nn.Module):\n",
    "    def __init__(self, RNN_TYPE, NUM_LAYERS, INPUT_SIZE, HIDDEN_SIZE, LINEAR_SIZE, OUTPUT_SIZE, BIDIRECTIONAL):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.rnn_type = RNN_TYPE\n",
    "        self.hidden_size = HIDDEN_SIZE\n",
    "        self.num_layers = NUM_LAYERS\n",
    "        self.input_size = INPUT_SIZE\n",
    "        self.linear_size = LINEAR_SIZE\n",
    "        self.output_size = OUTPUT_SIZE\n",
    "        self.bidirectional = BIDIRECTIONAL\n",
    "        \n",
    "        rnn_cell = getattr(nn, RNN_TYPE)\n",
    "\n",
    "        self.rnn = rnn_cell(\n",
    "                        input_size=self.input_size, \n",
    "                        hidden_size=self.hidden_size, \n",
    "                        num_layers=self.num_layers, \n",
    "                        bidirectional=self.bidirectional,\n",
    "                        dropout=0.4,\n",
    "                        batch_first=True\n",
    "                )\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "#                         nn.Linear(in_features=self.hidden_size*(self.bidirectional+1), out_features=self.output_size),\n",
    "                        nn.Linear(in_features=self.hidden_size*(self.bidirectional+1), out_features=self.linear_size),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(p=0.4),\n",
    "                        nn.Linear(in_features=self.linear_size, out_features=self.output_size),\n",
    "                )\n",
    "        \n",
    "        \n",
    "    def get_params(self):\n",
    "        \n",
    "        return {\n",
    "            \"RNN_TYPE\": self.rnn_type, \n",
    "            \"HIDDEN_SIZE\": self.hidden_size,\n",
    "            \"NUM_LAYERS\": self.num_layers,\n",
    "            \"INPUT_SIZE\": self.input_size,\n",
    "            \"LINEAR_SIZE\": self.linear_size,\n",
    "            \"OUTPUT_SIZE\": self.output_size,\n",
    "            \"BIDIRECTIONAL\": self.bidirectional\n",
    "        }\n",
    "    \n",
    "\n",
    "    def attention(self, lstm_output, last_hidden):\n",
    "        \n",
    "        attn_weights = torch.bmm(lstm_output, last_hidden.unsqueeze(2)).squeeze(2)\n",
    "        soft_attn_weights = F.softmax(attn_weights, dim=1)\n",
    "        new_hidden_state = torch.bmm(lstm_output.transpose(1, 2), soft_attn_weights.unsqueeze(2)).squeeze(2)\n",
    "\n",
    "        return new_hidden_state\n",
    "    \n",
    "    def forward(self, x, x_length):\n",
    "\n",
    "        x_packed = pack_padded_sequence(x, x_length, batch_first=True)\n",
    "        \n",
    "        x_rnn_out, _ = self.rnn(x_packed)\n",
    "        \n",
    "        x_unpacked, __ = pad_packed_sequence(x_rnn_out, batch_first=True)\n",
    "        \n",
    "        idx_last_hidden = (x_length - 1).view(-1, 1).expand(len(x_length), x_unpacked.size(2)).unsqueeze(1)\n",
    "        idx_last_hidden = idx_last_hidden.to(x.device)\n",
    "        x_last_hiddens = x_unpacked.gather(1, idx_last_hidden).squeeze(1)\n",
    "        \n",
    "        attention_out = self.attention(x_unpacked, x_last_hiddens)\n",
    "        x = self.head(attention_out)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(torch.nn.Module):\n",
    "    def __init__(self, NUM_LAYERS, INPUT_SIZE, HIDDEN_SIZE, LINEAR_SIZE, OUTPUT_SIZE, DROPOUT):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = HIDDEN_SIZE\n",
    "        self.num_layers = NUM_LAYERS\n",
    "        self.input_size = INPUT_SIZE\n",
    "        self.linear_size = LINEAR_SIZE\n",
    "        self.output_size = OUTPUT_SIZE\n",
    "        self.dropout = DROPOUT\n",
    "        \n",
    "        transformer_encoder_layer = nn.TransformerEncoderLayer(\n",
    "                        d_model=self.input_size, \n",
    "                        nhead=4, \n",
    "                        dim_feedforward=self.hidden_size, \n",
    "                        dropout=self.dropout, \n",
    "                        activation='relu'\n",
    "                )\n",
    "        \n",
    "        \n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "                        encoder_layer=transformer_encoder_layer, \n",
    "                        num_layers=self.num_layers, \n",
    "                        norm=None\n",
    "                )\n",
    "        \n",
    "        self.weighted_mean = nn.Conv1d(\n",
    "                        in_channels=self.input_size, \n",
    "                        out_channels=self.input_size, \n",
    "                        kernel_size=250, \n",
    "                        groups=self.input_size)\n",
    "    \n",
    "        self.head = nn.Sequential(\n",
    "                        nn.Dropout(p=0.2),\n",
    "                        nn.Linear(in_features=52, out_features=self.output_size),\n",
    "#                         nn.Linear(in_features=52, out_features=self.linear_size),\n",
    "#                         nn.ReLU(),\n",
    "#                         nn.Dropout(p=0.4),\n",
    "#                         nn.Linear(in_features=self.linear_size, out_features=self.output_size),\n",
    "                )\n",
    "        \n",
    "    \n",
    "    def get_params(self):\n",
    "        \n",
    "        return {\n",
    "                \"HIDDEN_SIZE\": self.hidden_size,\n",
    "                \"NUM_LAYERS\": self.num_layers,\n",
    "                \"INPUT_SIZE\": self.input_size,\n",
    "                \"LINEAR_SIZE\": self.linear_size,\n",
    "                \"OUTPUT_SIZE\": self.output_size,\n",
    "                \"DROPOUT\": self.dropout\n",
    "            }    \n",
    "    \n",
    "    \n",
    "    def forward(self, x, x_length=None):\n",
    "        \"\"\"\n",
    "        src: (S, N, E) = (sequence_length, batch_size, n_features)\n",
    "        src_key_padding_mask: (N, S) = (batch_size, sequence_length)\n",
    "        \"\"\"\n",
    "    \n",
    "        x_mask = torch.zeros(x.size(0), x.size(1), dtype=bool, device=x.device)\n",
    "        \n",
    "        for i in range(len(x)):\n",
    "            x_mask[i, x_length[i]:] = True\n",
    "\n",
    "        x = self.transformer_encoder(src=x.transpose(0, 1), src_key_padding_mask=x_mask)\n",
    "        x = x.permute(1, 2, 0)\n",
    "        x = self.weighted_mean(x)\n",
    "        x = x.squeeze(-1)\n",
    "        x = self.head(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_trans.input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiRNN(nn.Module) :\n",
    "    def __init__(self, RNN_TYPE, NUM_LAYERS, INPUT_SIZE, HIDDEN_SIZE, LINEAR_SIZE, OUTPUT_SIZE, BIDIRECTIONAL, DESCRIPTION):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rnn_type = RNN_TYPE\n",
    "        self.hidden_size = HIDDEN_SIZE\n",
    "        self.num_layers = NUM_LAYERS\n",
    "        self.input_size = INPUT_SIZE\n",
    "        self.linear_size = LINEAR_SIZE\n",
    "        self.output_size = OUTPUT_SIZE\n",
    "        self.bidirectional = BIDIRECTIONAL\n",
    "        self.description = DESCRIPTION\n",
    "        \n",
    "        rnn_cell = getattr(nn, RNN_TYPE)\n",
    "        \n",
    "        self.rnn = rnn_cell(\n",
    "                        input_size=self.input_size, \n",
    "                        hidden_size=self.hidden_size,\n",
    "                        num_layers=self.num_layers, \n",
    "                        bidirectional=self.bidirectional,\n",
    "                        batch_first=True,\n",
    "                        dropout=0.4\n",
    "                )    \n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "                        nn.Linear(in_features=self.hidden_size*(self.bidirectional+1), out_features=self.linear_size),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(p=0.4),\n",
    "                        nn.Linear(in_features=self.linear_size, out_features=self.output_size),\n",
    "                )\n",
    "    \n",
    "    def get_params(self):\n",
    "        \n",
    "        return {\n",
    "            \"RNN_TYPE\": self.rnn_type,\n",
    "            \"HIDDEN_SIZE\": self.hidden_size,\n",
    "            \"NUM_LAYERS\": self.num_layers,\n",
    "            \"INPUT_SIZE\": self.input_size,\n",
    "            \"LINEAR_SIZE\": self.linear_size,\n",
    "            \"OUTPUT_SIZE\": self.output_size,\n",
    "            \"BIDIRECTIONAL\": self.bidirectional,\n",
    "            \"DESCRIPTION\": self.description,\n",
    "            }\n",
    "            \n",
    "    def forward(self, x, x_length):\n",
    "        \n",
    "#         print(\"x\", x.size())\n",
    "        x, _ = self.rnn(x)\n",
    "#         print(\"x\", x.size())\n",
    "        x = self.head(x)\n",
    "#         print(\"x\", x.size())\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Loading best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention  multi_rnn  rnn  transformer\r\n"
     ]
    }
   ],
   "source": [
    "! ls final_saved_models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU_22May-14-28.pth  LSTM_22May-20-05.pth\r\n"
     ]
    }
   ],
   "source": [
    "! ls final_saved_models/attention/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU_22May-14-35.pth  LSTM_22May-16-20.pth\r\n"
     ]
    }
   ],
   "source": [
    "! ls final_saved_models/multi_rnn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU_22May-14-24.pth  LSTM_22May-20-05.pth\r\n"
     ]
    }
   ],
   "source": [
    "! ls final_saved_models/rnn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANSFORMER_22May-14-31.pth\r\n"
     ]
    }
   ],
   "source": [
    "! ls final_saved_models/transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_att_lstm = torch.load(f\"final_saved_models/attention/LSTM_22May-20-05.pth\")\n",
    "# checkpoint_att_gru = torch.load(f\"final_saved_models/attention/GRU_22May-14-28.pth\")\n",
    "\n",
    "# checkpoint_multi_gru = torch.load(f\"final_saved_models/multi_rnn/GRU_22May-14-35.pth\")\n",
    "# checkpoint_multi_lstm = torch.load(f\"final_saved_models/multi_rnn/LSTM_22May-16-20.pth\")\n",
    "\n",
    "# checkpoint_rnn_lstm = torch.load(f\"final_saved_models/rnn/LSTM_22May-20-05.pth\")\n",
    "# checkpoint_rnn_gru = torch.load(f\"final_saved_models/rnn/GRU_22May-14-24.pth\")\n",
    "\n",
    "\n",
    "# checkpoint_trans = torch.load(f\"final_saved_models/transformer/TRANSFORMER_22May-14-31.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_att_lstm = f\"final_saved_models/attention/LSTM_22May-20-05.pth\"\n",
    "path_att_gru = f\"final_saved_models/attention/GRU_22May-14-28.pth\"\n",
    "\n",
    "path_multi_gru = f\"final_saved_models/multi_rnn/GRU_22May-14-35.pth\"\n",
    "path_multi_lstm = f\"final_saved_models/multi_rnn/LSTM_22May-16-20.pth\"\n",
    "\n",
    "path_rnn_lstm = f\"final_saved_models/rnn/LSTM_22May-20-05.pth\"\n",
    "path_rnn_gru = f\"final_saved_models/rnn/GRU_22May-14-24.pth\"\n",
    "\n",
    "\n",
    "path_trans = f\"final_saved_models/transformer/TRANSFORMER_22May-14-31.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(path):\n",
    "    \n",
    "    checkpoint = torch.load(path)\n",
    "    model = getattr(sys.modules[__name__], checkpoint['model'])(**checkpoint['params'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    for parameter in model.parameters():\n",
    "            parameter.requires_grad = False\n",
    "\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_att_lstm = get_model(f\"final_saved_models/attention/LSTM_22May-20-05.pth\")\n",
    "model_att_gru = get_model(f\"final_saved_models/attention/GRU_22May-14-28.pth\")\n",
    "\n",
    "# model_multi_gru = get_model(f\"final_saved_models/multi_rnn/GRU_22May-14-35.pth\")\n",
    "# model_multi_lstm = get_model(f\"final_saved_models/multi_rnn/LSTM_22May-16-20.pth\")\n",
    "\n",
    "# model_rnn_lstm = get_model(f\"final_saved_models/rnn/LSTM_22May-20-05.pth\")\n",
    "# model_rnn_gru = get_model(f\"final_saved_models/rnn/GRU_22May-14-24.pth\")\n",
    "\n",
    "model_trans = get_model(f\"final_saved_models/transformer/TRANSFORMER_22May-14-31.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Metrics and graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates TPR, FPR and ACCURACY per class for multiple simulation runs\n",
    "    https://stackoverflow.com/questions/50666091/true-positive-rate-and-false-positive-rate-tpr-fpr-for-multi-class-data-in-py\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : \n",
    "        type: np.array \n",
    "        shape : (number of simulation runs)\n",
    "        description: true classes for simulation runs\n",
    "    \n",
    "    y_pred : np.array\n",
    "    \n",
    "        type: np.array \n",
    "        shape : (number of simulation runs)\n",
    "        description: predicted classes for simulation runs\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    TPR : \n",
    "        type: list of floats\n",
    "        shape: (number of classes)\n",
    "        description: True Positive Rate per class\n",
    "    FPR : \n",
    "        type: list of floats\n",
    "        shape: (number of classes)\n",
    "        description: False Positive Rate per class\n",
    "    ACCURACY : \n",
    "        type: list of floats\n",
    "        shape: (number of classes)\n",
    "        description: Accuracy \"one vs all\" per class\n",
    "    \"\"\"\n",
    "    \n",
    "    conf = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    FP = conf.sum(axis=0) - np.diag(conf)\n",
    "    FN = conf.sum(axis=1) - np.diag(conf)\n",
    "    TP = np.diag(conf)\n",
    "    TN = conf.sum() - (FP + FN + TP)\n",
    "    \n",
    "    TPR = TP / (TP + FN)\n",
    "    FPR = FP / (FP + TN)\n",
    "\n",
    "    ACCURACY = (TP + TN) / (TP + TN + FP + FN)\n",
    "    \n",
    "    return TPR, FPR, ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_true_idx(arr):\n",
    "    idx = np.where(arr == True)[0]\n",
    "    \n",
    "    if len(idx) == 0:\n",
    "        return -999\n",
    "    else:\n",
    "        return idx.min() + 1\n",
    "\n",
    "def get_detection_delay(y_true, y_pred) -> dict():\n",
    "    \"\"\"\n",
    "    Calculates detection delay for every simulation run\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : \n",
    "        type : np.array \n",
    "        shape : (number of simulation runs)\n",
    "        description : true classes for simulation runs\n",
    "    \n",
    "    y_pred : np.array \n",
    "        type : np.array \n",
    "        shape : (number of simulation runs, simulation runs' lengths)\n",
    "        description: predicted classes for every sample for every simulation runs\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    detection_delay :\n",
    "        type : dict\n",
    "        keys : classes from 0 to 20\n",
    "        description : dict of detection delays for every class, nan means true class wasn't predicted\n",
    "    \n",
    "    Commentary:\n",
    "        If you want to get avarage detection delays per class, you need to calulate avg of detection_delay[key]\n",
    "        for every key \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    detection_delay = defaultdict(list)\n",
    "    \n",
    "    correct = y_pred == y_true[..., np.newaxis]\n",
    "    first_true_idxs = np.apply_along_axis(func1d=get_first_true_idx, arr=correct, axis=1)\n",
    "    \n",
    "    first_true_idxs = first_true_idxs.astype(float)\n",
    "    first_true_idxs[first_true_idxs == -999] = np.NaN\n",
    "\n",
    "    for i, (cls, idx) in enumerate(zip(y_true, first_true_idxs)):\n",
    "        detection_delay[cls].append(idx)\n",
    "    return detection_delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del a3, a4\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading test data in .R format\n",
    "a3 = py.read_r(\"../../data/raw/dataverse_files/TEP_FaultFree_Testing.RData\")\n",
    "a4 = py.read_r(\"../../data/raw/dataverse_files/TEP_Faulty_Testing.RData\")\n",
    "\n",
    "raw_test = pd.concat([a3['fault_free_testing'], a4['faulty_testing']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test[features] = scaler.transform(raw_test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test['index'] = raw_test['faultNumber'] * 500 + raw_test['simulationRun'] - 1\n",
    "raw_test = raw_test.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faultNumber</th>\n",
       "      <th>simulationRun</th>\n",
       "      <th>sample</th>\n",
       "      <th>xmeas_1</th>\n",
       "      <th>xmeas_2</th>\n",
       "      <th>xmeas_3</th>\n",
       "      <th>xmeas_4</th>\n",
       "      <th>xmeas_5</th>\n",
       "      <th>xmeas_6</th>\n",
       "      <th>xmeas_7</th>\n",
       "      <th>xmeas_8</th>\n",
       "      <th>xmeas_9</th>\n",
       "      <th>xmeas_10</th>\n",
       "      <th>xmeas_11</th>\n",
       "      <th>xmeas_12</th>\n",
       "      <th>xmeas_13</th>\n",
       "      <th>xmeas_14</th>\n",
       "      <th>xmeas_15</th>\n",
       "      <th>xmeas_16</th>\n",
       "      <th>xmeas_17</th>\n",
       "      <th>xmeas_18</th>\n",
       "      <th>xmeas_19</th>\n",
       "      <th>xmeas_20</th>\n",
       "      <th>xmeas_21</th>\n",
       "      <th>xmeas_22</th>\n",
       "      <th>xmeas_23</th>\n",
       "      <th>xmeas_24</th>\n",
       "      <th>xmeas_25</th>\n",
       "      <th>xmeas_26</th>\n",
       "      <th>xmeas_27</th>\n",
       "      <th>xmeas_28</th>\n",
       "      <th>xmeas_29</th>\n",
       "      <th>xmeas_30</th>\n",
       "      <th>xmeas_31</th>\n",
       "      <th>xmeas_32</th>\n",
       "      <th>xmeas_33</th>\n",
       "      <th>xmeas_34</th>\n",
       "      <th>xmeas_35</th>\n",
       "      <th>xmeas_36</th>\n",
       "      <th>xmeas_37</th>\n",
       "      <th>xmeas_38</th>\n",
       "      <th>xmeas_39</th>\n",
       "      <th>xmeas_40</th>\n",
       "      <th>xmeas_41</th>\n",
       "      <th>xmv_1</th>\n",
       "      <th>xmv_2</th>\n",
       "      <th>xmv_3</th>\n",
       "      <th>xmv_4</th>\n",
       "      <th>xmv_5</th>\n",
       "      <th>xmv_6</th>\n",
       "      <th>xmv_7</th>\n",
       "      <th>xmv_8</th>\n",
       "      <th>xmv_9</th>\n",
       "      <th>xmv_10</th>\n",
       "      <th>xmv_11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>0.64</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>1.83</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.64</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.71</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-1.57</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>1.36</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.29</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>-1.49</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.48</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.29</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.48</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       faultNumber  simulationRun  sample  xmeas_1  xmeas_2  xmeas_3  xmeas_4  \\\n",
       "index                                                                           \n",
       "0.00             0           1.00       1    -0.06     0.20    -0.37     0.40   \n",
       "0.00             0           1.00       2    -0.06    -0.50     0.58     0.12   \n",
       "0.00             0           1.00       3    -0.08    -0.48     0.01    -0.22   \n",
       "0.00             0           1.00       4    -0.06    -0.83     0.12    -0.10   \n",
       "0.00             0           1.00       5    -0.30    -0.19     0.60    -0.17   \n",
       "\n",
       "       xmeas_5  xmeas_6  xmeas_7  xmeas_8  xmeas_9  xmeas_10  xmeas_11  \\\n",
       "index                                                                    \n",
       "0.00      0.67     0.35    -0.22    -0.10     0.14     -0.11      0.24   \n",
       "0.00      0.42     0.71    -0.23     0.18    -0.28     -0.10      0.20   \n",
       "0.00      0.11    -0.27    -0.25    -0.26    -0.28     -0.11      0.13   \n",
       "0.00      0.42    -0.11    -0.25    -0.02    -0.28     -0.11      0.11   \n",
       "0.00     -0.00     0.12    -0.20    -0.38    -0.00     -0.30      0.29   \n",
       "\n",
       "       xmeas_12  xmeas_13  xmeas_14  xmeas_15  xmeas_16  xmeas_17  xmeas_18  \\\n",
       "index                                                                         \n",
       "0.00       0.68     -0.21     -0.49      0.64     -0.23      1.83     -0.13   \n",
       "0.00      -0.48     -0.21     -1.57     -0.60     -0.24      1.36     -0.15   \n",
       "0.00       1.29     -0.24     -0.73     -0.80     -0.26     -1.49     -0.16   \n",
       "0.00       0.68     -0.24     -0.83      0.68     -0.25      0.68     -0.17   \n",
       "0.00       0.07     -0.19      0.50     -0.75     -0.24     -0.38     -0.15   \n",
       "\n",
       "       xmeas_19  xmeas_20  xmeas_21  xmeas_22  xmeas_23  xmeas_24  xmeas_25  \\\n",
       "index                                                                         \n",
       "0.00      -0.20      0.08      0.17      0.07      0.12      0.06     -0.20   \n",
       "0.00      -0.24      0.12      0.09      0.06      0.12      0.06     -0.20   \n",
       "0.00      -0.23      0.10      0.23      0.09      0.30      0.48     -0.46   \n",
       "0.00      -0.23      0.09      0.02      0.08      0.30      0.48     -0.46   \n",
       "0.00      -0.24      0.10      0.26      0.60      0.24      0.17     -0.35   \n",
       "\n",
       "       xmeas_26  xmeas_27  xmeas_28  xmeas_29  xmeas_30  xmeas_31  xmeas_32  \\\n",
       "index                                                                         \n",
       "0.00       0.06      0.07      0.22      0.12      0.08     -0.20      0.03   \n",
       "0.00       0.06      0.07      0.22      0.12      0.08     -0.20      0.03   \n",
       "0.00       0.86      0.04     -0.07      0.29     -0.47     -0.29     -0.20   \n",
       "0.00       0.86      0.04     -0.07      0.29     -0.47     -0.29     -0.20   \n",
       "0.00      -1.32     -0.40      0.14      0.11      0.26     -0.35     -0.24   \n",
       "\n",
       "       xmeas_33  xmeas_34  xmeas_35  xmeas_36  xmeas_37  xmeas_38  xmeas_39  \\\n",
       "index                                                                         \n",
       "0.00       0.08      0.24      0.18      0.19     -0.01     -0.04      0.09   \n",
       "0.00       0.08      0.24      0.18      0.19     -0.01     -0.04      0.09   \n",
       "0.00       0.27      0.33      0.23      0.30     -0.01     -0.04      0.09   \n",
       "0.00       0.27      0.33      0.23      0.30     -0.01     -0.04      0.09   \n",
       "0.00       0.04      0.40      0.09     -0.33     -0.01     -0.04      0.09   \n",
       "\n",
       "       xmeas_40  xmeas_41  xmv_1  xmv_2  xmv_3  xmv_4  xmv_5  xmv_6  xmv_7  \\\n",
       "index                                                                        \n",
       "0.00      -0.05      0.06  -0.18   0.04  -0.28  -0.48  -0.05   0.02   0.68   \n",
       "0.00      -0.05      0.06  -0.02  -0.20  -0.28  -0.37  -0.04   0.00  -0.48   \n",
       "0.00      -0.05      0.06  -0.03  -0.06  -0.26  -0.35  -0.06   0.01   1.29   \n",
       "0.00      -0.05      0.06   0.05  -0.09  -0.28  -0.17  -0.08   0.02   0.68   \n",
       "0.00      -0.05      0.06  -0.39  -0.19  -0.42  -0.18  -0.04  -0.18   0.08   \n",
       "\n",
       "       xmv_8  xmv_9  xmv_10  xmv_11  \n",
       "index                                \n",
       "0.00    0.64  -0.19    0.01   -0.69  \n",
       "0.00   -0.60  -0.17   -0.14   -0.55  \n",
       "0.00   -0.80  -0.17   -0.06    0.33  \n",
       "0.00    0.68  -0.18   -0.12   -0.34  \n",
       "0.00   -0.75  -0.17   -0.09   -0.02  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTEST_uni(Dataset):\n",
    "\n",
    "    def __init__(self, X, seq_length):\n",
    "    \n",
    "        self.X = X\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        self.features = [\n",
    "                'xmeas_1', 'xmeas_2', 'xmeas_3', 'xmeas_4', 'xmeas_5', 'xmeas_6', 'xmeas_7', 'xmeas_8', 'xmeas_9', \n",
    "                'xmeas_10', 'xmeas_11', 'xmeas_12', 'xmeas_13', 'xmeas_14', 'xmeas_15', 'xmeas_16', 'xmeas_17', \n",
    "                'xmeas_18', 'xmeas_19', 'xmeas_20', 'xmeas_21', 'xmeas_22', 'xmeas_23', 'xmeas_24', 'xmeas_25', \n",
    "                'xmeas_26', 'xmeas_27', 'xmeas_28', 'xmeas_29', 'xmeas_30', 'xmeas_31', 'xmeas_32', 'xmeas_33', \n",
    "                'xmeas_34', 'xmeas_35', 'xmeas_36', 'xmeas_37', 'xmeas_38', 'xmeas_39', 'xmeas_40', 'xmeas_41', \n",
    "                'xmv_1', 'xmv_2', 'xmv_3', 'xmv_4', 'xmv_5', 'xmv_6', 'xmv_7', 'xmv_8', 'xmv_9', 'xmv_10', 'xmv_11'\n",
    "            ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.index.nunique()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        features = self.X.loc[idx][self.features].values[FAULT_START_TEST : (FAULT_START_TEST+self.seq_length), :]\n",
    "        target = self.X.loc[idx]['faultNumber'].unique()[0]\n",
    "\n",
    "        features = torch.tensor(features, dtype=torch.float)\n",
    "        target = torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "        return features, target\n",
    "    \n",
    "\n",
    "class DataTEST_multi(Dataset):\n",
    "\n",
    "    def __init__(self, X):\n",
    "    \n",
    "        self.X = X\n",
    "        \n",
    "        self.features = [\n",
    "                'xmeas_1', 'xmeas_2', 'xmeas_3', 'xmeas_4', 'xmeas_5', 'xmeas_6', 'xmeas_7', 'xmeas_8', 'xmeas_9', \n",
    "                'xmeas_10', 'xmeas_11', 'xmeas_12', 'xmeas_13', 'xmeas_14', 'xmeas_15', 'xmeas_16', 'xmeas_17', \n",
    "                'xmeas_18', 'xmeas_19', 'xmeas_20', 'xmeas_21', 'xmeas_22', 'xmeas_23', 'xmeas_24', 'xmeas_25', \n",
    "                'xmeas_26', 'xmeas_27', 'xmeas_28', 'xmeas_29', 'xmeas_30', 'xmeas_31', 'xmeas_32', 'xmeas_33', \n",
    "                'xmeas_34', 'xmeas_35', 'xmeas_36', 'xmeas_37', 'xmeas_38', 'xmeas_39', 'xmeas_40', 'xmeas_41', \n",
    "                'xmv_1', 'xmv_2', 'xmv_3', 'xmv_4', 'xmv_5', 'xmv_6', 'xmv_7', 'xmv_8', 'xmv_9', 'xmv_10', 'xmv_11'\n",
    "            ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.index.nunique()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        features = self.X.loc[idx][self.features].values[FAULT_START_TEST:, :]\n",
    "        target = self.X.loc[idx]['faultNumber'].values[FAULT_START_TEST:]\n",
    "\n",
    "        features = torch.tensor(features, dtype=torch.float)\n",
    "        target = torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "        return features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_multi(model):\n",
    "    \n",
    "    test_ds = DataTEST_multi(raw_test)\n",
    "    test_dl = DataLoader(test_ds, batch_size=512)\n",
    "\n",
    "    metrics = dict()\n",
    "    y_ans_test_all = []\n",
    "\n",
    "    y_ans_test, y_true_test = [], []\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    model.eval()\n",
    "    for (X_batch_test, y_batch_test) in tqdm(test_dl):\n",
    "\n",
    "        X_batch_test, y_batch_test = X_batch_test.to(device), y_batch_test.to(device)\n",
    "\n",
    "        y_pred_test = model(X_batch_test, None)\n",
    "\n",
    "        y_pred_prob = F.softmax(y_pred_test.cpu(), dim=-1)\n",
    "        y_pred_class = y_pred_prob.max(dim=-1)[1]\n",
    "\n",
    "        y_ans_test.append(y_pred_class.cpu().numpy())\n",
    "        y_true_test.append(y_batch_test.cpu().numpy())\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "    print(f\"seq_length time: {end - start}\")  \n",
    "    \n",
    "    y_ans_test_all = np.concatenate(y_ans_test, axis=0)\n",
    "    y_true_test_all = np.concatenate(y_true_test, axis=0)\n",
    "    \n",
    "    return y_ans_test_all, y_true_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def inference_uni(model):  \n",
    "    \n",
    "    SEQ_LEN = 800\n",
    "    \n",
    "    y_ans_test_all, y_true_test_all = [], []\n",
    "\n",
    "    test_ds = DataTEST_uni(raw_test, seq_length=SEQ_LEN)\n",
    "    test_dl = DataLoader(test_ds, batch_size=512)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for (X_batch_test, y_batch_test) in tqdm(test_dl):\n",
    "\n",
    "        y_ans_test, y_true_test = [], []\n",
    "        X_batch_test, y_batch_test = X_batch_test.to(device), y_batch_test.to(device)\n",
    "\n",
    "        for i in range(2, SEQ_LEN):\n",
    "\n",
    "            X_batch_lengths_test = torch.tensor([i]*len(X_batch_test)).to(device)            \n",
    "            y_pred_test = model(X_batch_test[:, :i, :], X_batch_lengths_test)\n",
    "\n",
    "            y_pred_prob = F.softmax(y_pred_test.cpu(), dim=-1)\n",
    "            y_pred_class = y_pred_prob.max(dim=-1)[1]\n",
    "\n",
    "            y_ans_test.append(y_pred_class.tolist())\n",
    "            y_true_test.append(y_batch_test.tolist())\n",
    "\n",
    "            end = time.time()\n",
    "\n",
    "        y_ans_test_all.append(np.array(y_ans_test).T)\n",
    "        y_true_test_all.append(np.array(y_true_test).T)\n",
    "\n",
    "    y_ans_test_all = np.concatenate(y_ans_test_all)   \n",
    "    y_true_test_all = np.concatenate(y_true_test_all)   \n",
    "\n",
    "    return y_ans_test_all, y_true_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "\n",
    "    sequences = [x[0] for x in batch]\n",
    "    labels = [x[1] for x in batch]\n",
    "        \n",
    "    lengths = torch.LongTensor([len(x) for x in sequences])\n",
    "    lengths, idx = lengths.sort(0, descending=True)\n",
    "    \n",
    "    sequences = [sequences[i] for i in idx]\n",
    "    \n",
    "    labels = torch.tensor(labels, dtype=torch.long)[idx]\n",
    "    \n",
    "#     sequences_padded = pad_sequence(sequences, batch_first=True)\n",
    "    \n",
    "    for seq in sequences:\n",
    "        print(seq.size())\n",
    "        sequences_padded = F.pad(seq, pad=(0, 250-len(seq)), mode='constant', value=0)\n",
    "    \n",
    "    sequences_padded = torch.tensor(sequences_padded)\n",
    "\n",
    "    return sequences_padded, lengths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_trans(model):  \n",
    "    \n",
    "    SEQ_LEN = 800\n",
    "    \n",
    "    y_ans_test_all, y_true_test_all = [], []\n",
    "    \n",
    "    BATCH_SIZE = 512\n",
    "\n",
    "    test_ds = DataTEST_uni(raw_test, seq_length=SEQ_LEN)\n",
    "    test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for (X_batch_test, y_batch_test) in tqdm(test_dl):\n",
    "\n",
    "        y_ans_test, y_true_test = [], []\n",
    "#         X_batch_test, y_batch_test = X_batch_test.to(device), y_batch_test.to(device)\n",
    "\n",
    "        for i in range(1, SEQ_LEN+1):\n",
    "        \n",
    "            start = max(0, i-250)\n",
    "            end = i\n",
    "            length = end - start\n",
    "            \n",
    "            X_source = torch.zeros(X_batch_test.size(0), 250, X_batch_test.size(2))\n",
    "            X_source[:, :end, :] = X_batch_test[:, start:end, :]\n",
    "            \n",
    "#             print(start, end, length)\n",
    "#             print(X_batch_test[:, start:end, :].size())\n",
    "#             print(\"X_source\", X_source.size())\n",
    "#             print(\"X_source\", X_source[:, -5:, :])\n",
    "            \n",
    "            X_source, y_batch_test = X_source.to(device), y_batch_test.to(device)\n",
    "            \n",
    "            X_batch_lengths_test = torch.tensor([length]*BATCH_SIZE).to(device)            \n",
    "#             y_pred_test = model(X_batch_test[:, :i, :], X_batch_lengths_test)\n",
    "            y_pred_test = model(X_source, X_batch_lengths_test)\n",
    "\n",
    "            y_pred_prob = F.softmax(y_pred_test.cpu(), dim=-1)\n",
    "            y_pred_class = y_pred_prob.max(dim=-1)[1]\n",
    "\n",
    "            y_ans_test.append(y_pred_class.tolist())\n",
    "            y_true_test.append(y_batch_test.tolist())\n",
    "\n",
    "            end = time.time()\n",
    "\n",
    "        y_ans_test_all.append(np.array(y_ans_test).T)\n",
    "        y_true_test_all.append(np.array(y_true_test).T)\n",
    "\n",
    "    y_ans_test_all = np.concatenate(y_ans_test_all)   \n",
    "    y_true_test_all = np.concatenate(y_true_test_all)   \n",
    "\n",
    "    return y_ans_test_all, y_true_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "att_gru  att_lstm  multi_gru  multi_lstm  rnn_gru  rnn_lstm  trans\r\n"
     ]
    }
   ],
   "source": [
    "! ls final_preds_saved/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_classes, y_true_classes = inference_multi(model_multi_gru)\n",
    "\n",
    "# np.savetxt(\"final_preds_saved/multi_gru/y_pred_classes.csv\", y_pred_classes, delimiter=\",\")   \n",
    "# np.savetxt(\"final_preds_saved/multi_gru/y_true_classes.csv\", y_true_classes, delimiter=\",\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_classes, y_true_classes = inference_multi(model_multi_lstm)\n",
    "\n",
    "# np.savetxt(\"final_preds_saved/multi_lstm/y_pred_classes.csv\", y_pred_classes, delimiter=\",\")   \n",
    "# np.savetxt(\"final_preds_saved/multi_lstm/y_true_classes.csv\", y_true_classes, delimiter=\",\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# y_pred_classes, y_true_classes = inference_uni(model_rnn_gru)\n",
    "\n",
    "# np.savetxt(\"final_preds_saved/rnn_gru/y_pred_classes.csv\", y_pred_classes, delimiter=\",\")   \n",
    "# np.savetxt(\"final_preds_saved/rnn_gru/y_true_classes.csv\", y_true_classes, delimiter=\",\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_classes, y_true_classes = inference_uni(model_rnn_lstm)\n",
    "\n",
    "# np.savetxt(\"final_preds_saved/rnn_lstm/y_pred_classes.csv\", y_pred_classes, delimiter=\",\")   \n",
    "# np.savetxt(\"final_preds_saved/rnn_lstm/y_true_classes.csv\", y_true_classes, delimiter=\",\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_classes, y_true_classes = inference_uni(model_att_lstm)\n",
    "\n",
    "# np.savetxt(\"final_preds_saved/att_lstm/y_pred_classes.csv\", y_pred_classes, delimiter=\",\")   \n",
    "# np.savetxt(\"final_preds_saved/att_lstm/y_true_classes.csv\", y_true_classes, delimiter=\",\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_classes, y_true_classes = inference_uni(model_att_gru)\n",
    "\n",
    "# np.savetxt(\"final_preds_saved/att_gru/y_pred_classes.csv\", y_pred_classes, delimiter=\",\")   \n",
    "# np.savetxt(\"final_preds_saved/att_gru/y_true_classes.csv\", y_true_classes, delimiter=\",\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(torch.nn.Module):\n",
    "    def __init__(self, NUM_LAYERS, INPUT_SIZE, HIDDEN_SIZE, LINEAR_SIZE, OUTPUT_SIZE, DROPOUT):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = HIDDEN_SIZE\n",
    "        self.num_layers = NUM_LAYERS\n",
    "        self.input_size = INPUT_SIZE\n",
    "        self.linear_size = LINEAR_SIZE\n",
    "        self.output_size = OUTPUT_SIZE\n",
    "        self.dropout = DROPOUT\n",
    "        \n",
    "        transformer_encoder_layer = nn.TransformerEncoderLayer(\n",
    "                        d_model=self.input_size, \n",
    "                        nhead=4, \n",
    "                        dim_feedforward=self.hidden_size, \n",
    "                        dropout=self.dropout, \n",
    "                        activation='relu'\n",
    "                )\n",
    "        \n",
    "        \n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "                        encoder_layer=transformer_encoder_layer, \n",
    "                        num_layers=self.num_layers, \n",
    "                        norm=None\n",
    "                )\n",
    "        \n",
    "        self.weighted_mean = nn.Conv1d(\n",
    "                        in_channels=self.input_size, \n",
    "                        out_channels=self.input_size, \n",
    "                        kernel_size=250, \n",
    "                        groups=self.input_size)\n",
    "    \n",
    "        self.head = nn.Sequential(\n",
    "                        nn.Dropout(p=0.2),\n",
    "                        nn.Linear(in_features=52, out_features=self.output_size),\n",
    "#                         nn.Linear(in_features=52, out_features=self.linear_size),\n",
    "#                         nn.ReLU(),\n",
    "#                         nn.Dropout(p=0.4),\n",
    "#                         nn.Linear(in_features=self.linear_size, out_features=self.output_size),\n",
    "                )\n",
    "        \n",
    "    \n",
    "    def get_params(self):\n",
    "        \n",
    "        return {\n",
    "                \"HIDDEN_SIZE\": self.hidden_size,\n",
    "                \"NUM_LAYERS\": self.num_layers,\n",
    "                \"INPUT_SIZE\": self.input_size,\n",
    "                \"LINEAR_SIZE\": self.linear_size,\n",
    "                \"OUTPUT_SIZE\": self.output_size,\n",
    "                \"DROPOUT\": self.dropout\n",
    "            }    \n",
    "    \n",
    "    \n",
    "    def forward(self, x, x_length=None):\n",
    "        \"\"\"\n",
    "        src: (S, N, E) = (sequence_length, batch_size, n_features)\n",
    "        src_key_padding_mask: (N, S) = (batch_size, sequence_length)\n",
    "        \"\"\"\n",
    "    \n",
    "        x_mask = torch.zeros(x.size(0), 250, dtype=bool, device=x.device)\n",
    "        \n",
    "#         print(\"x\", x.size())\n",
    "#         print(\"x_mask\", x_mask.size())\n",
    "#         print(\"x_length\", x_length.size())\n",
    "        \n",
    "        for i in range(len(x)):\n",
    "#             print(i)\n",
    "#             print(x_length[i])\n",
    "            x_mask[i, x_length[i]:] = True\n",
    "            \n",
    "#         print(x.size(), x_mask.size())\n",
    "\n",
    "        x = self.transformer_encoder(src=x.transpose(0, 1), src_key_padding_mask=x_mask)\n",
    "        x = x.permute(1, 2, 0)\n",
    "        \n",
    "#         print(x.size())\n",
    "        \n",
    "        x = self.weighted_mean(x)\n",
    "        x = x.squeeze(-1)\n",
    "        x = self.head(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trans = get_model(f\"final_saved_models/transformer/TRANSFORMER_22May-14-31.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6afda310be047f48280d9266a171d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes, y_true_classes = inference_trans(model_trans)\n",
    "\n",
    "np.savetxt(\"final_preds_saved/trans/y_pred_classes.csv\", y_pred_classes, delimiter=\",\")   \n",
    "np.savetxt(\"final_preds_saved/trans/y_true_classes.csv\", y_true_classes, delimiter=\",\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10500, 800)"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 15, 13, 13, 18, 13, 13, 13,  9, 13,  9,  9,  9, 13, 18, 18, 18,\n",
       "       18, 18, 18, 18,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  9,  0,  9,  9,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  9,  0,  9,\n",
       "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "        9,  9,  9,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,  0,\n",
       "       15, 15, 15,  0,  0, 15, 15, 15, 15, 15,  0,  0,  0,  0,  0,  0, 15,\n",
       "        0, 15,  0,  0, 15, 15,  0, 15,  0, 15,  0, 15, 15, 15,  0, 15, 15,\n",
       "        0,  0,  0,  0, 15, 15, 15, 15, 15,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0, 15, 15, 15,  0,  0,  0,  0,  0,  0,  0,  9,  0,  9,  9,  9,  9,\n",
       "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "        9,  9,  9,  9,  9,  9, 15,  9,  9,  9,  9,  9,  0,  9,  0,  0,  0,\n",
       "        9,  9,  9,  9,  9,  0,  0,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  0,  0,\n",
       "        0])"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_classes[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "models['multi_gru'] = {}\n",
    "models['multi_lstm'] = {}\n",
    "\n",
    "models['rnn_gru'] = {}\n",
    "models['rnn_lstm'] = {}\n",
    "\n",
    "models['attention_gru'] = {}\n",
    "models['attention_lstm'] = {}\n",
    "\n",
    "models['transformer'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "models['multi_gru']['pred'] = \"final_preds_saved/multi_gru/y_pred_classes.csv\"\n",
    "models['multi_gru']['true'] = \"final_preds_saved/multi_gru/y_true_classes.csv\"\n",
    "\n",
    "models['multi_lstm']['pred'] = \"final_preds_saved/multi_lstm/y_pred_classes.csv\"\n",
    "models['multi_lstm']['true'] = \"final_preds_saved/multi_lstm/y_true_classes.csv\"\n",
    "\n",
    "models['rnn_gru']['pred'] = \"final_preds_saved/rnn_gru/y_pred_classes.csv\"\n",
    "models['rnn_gru']['true'] = \"final_preds_saved/rnn_gru/y_true_classes.csv\"\n",
    "\n",
    "models['rnn_lstm']['pred'] = \"final_preds_saved/rnn_lstm/y_pred_classes.csv\"\n",
    "models['rnn_lstm']['true'] = \"final_preds_saved/rnn_lstm/y_true_classes.csv\"\n",
    "\n",
    "models['attention_gru']['pred'] = \"final_preds_saved/att_gru/y_pred_classes.csv\"\n",
    "models['attention_gru']['true'] = \"final_preds_saved/att_gru/y_true_classes.csv\"\n",
    "\n",
    "models['attention_lstm']['pred'] = \"final_preds_saved/att_lstm/y_pred_classes.csv\"\n",
    "models['attention_lstm']['true'] = \"final_preds_saved/att_lstm/y_true_classes.csv\"\n",
    "\n",
    "models['transformer']['pred'] = \"final_preds_saved/trans/y_pred_classes.csv\"\n",
    "models['transformer']['true'] = \"final_preds_saved/trans/y_true_classes.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df37acd27294240bd07658ffcbcbdc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "STEPS = [5, 50, 100, -1]\n",
    "\n",
    "for model in tqdm(models.keys()):\n",
    "    \n",
    "    y_true_classes = np.genfromtxt(models[model]['true'], delimiter=',')\n",
    "    y_pred_classes = np.genfromtxt(models[model]['pred'], delimiter=',')\n",
    "    \n",
    "    detection_delay = get_detection_delay(y_true=y_true_classes[:, -1], y_pred=y_pred_classes)\n",
    "    \n",
    "    detection_delay_mean = {}\n",
    "    for (k, v) in detection_delay.items():\n",
    "        detection_delay_mean[k] = np.nanmean(v)\n",
    "        \n",
    "    models[model]['detection_delay'] = detection_delay_mean\n",
    "    \n",
    "    for step in STEPS:\n",
    "        \n",
    "        TPR, FPR, ACCURACY = get_metrics(y_true=y_true_classes[:, -1], y_pred=y_pred_classes[:, step])\n",
    "        \n",
    "        models[model][step] = {}\n",
    "        \n",
    "        models[model][step]['TPR'] = TPR\n",
    "        models[model][step]['FPR'] = FPR\n",
    "        models[model][step]['ACCURACY'] = ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "models['multi_gru']['marker_style'] = '*'\n",
    "models['multi_gru']['marker_color'] = 'olivedrab'\n",
    "models['multi_gru']['label'] = 'gru type: 2'\n",
    "\n",
    "models['multi_lstm']['marker_style'] = '*'\n",
    "models['multi_lstm']['marker_color'] = 'yellowgreen'\n",
    "models['multi_lstm']['label'] = 'lstm type: 2'\n",
    "\n",
    "models['rnn_gru']['marker_style'] = 'X'\n",
    "models['rnn_gru']['marker_color'] = 'gold'\n",
    "models['rnn_gru']['label'] = 'gru type: 1'\n",
    "\n",
    "models['rnn_lstm']['marker_style'] = 'X'\n",
    "models['rnn_lstm']['marker_color'] = 'khaki'\n",
    "models['rnn_lstm']['label'] = 'lstm type: 1'\n",
    "\n",
    "models['attention_gru']['marker_style'] = 'x'\n",
    "models['attention_gru']['marker_color'] = 'skyblue'\n",
    "models['attention_gru']['label'] = 'gru + att type: 1'\n",
    "\n",
    "models['attention_lstm'] ['marker_style'] = 'x'\n",
    "models['attention_lstm'] ['marker_color'] = 'steelblue'\n",
    "models['attention_lstm']['label'] = 'lstm + att type: 1'\n",
    "\n",
    "models['transformer']['marker_style'] = '.'\n",
    "models['transformer']['marker_color'] = 'pink'\n",
    "models['transformer']['label'] = 'transformer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_results(step, tpr_limits, fpr_limits, acc_limits):\n",
    "    \n",
    "    classes = np.arange(21)\n",
    "    xticks = [\"fault_\" + str(c) if c > 0 else \"normal\" for c in classes]\n",
    "    cols_order = [\n",
    "                    'gru type: 1', 'lstm type: 1', 'gru + att type: 1', 'lstm + att type: 1', 'transformer', \n",
    "                    'gru type: 2', 'lstm type: 2'\n",
    "            ]\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=4, ncols=1, figsize=(10, 25))\n",
    "\n",
    "    ax[0].title.set_text(f'TPR (true positive rate) per class')\n",
    "    ax[0].set_xticks(classes)\n",
    "    ax[0].set_xticklabels(xticks, rotation=30)\n",
    "    ax[0].set_xlabel('class')\n",
    "    ax[0].set_ylabel(f'TPR')\n",
    "    ax[0].set_ylim(tpr_limits)\n",
    "\n",
    "\n",
    "    ax[1].title.set_text(f'FPR (false positive rate) per class')\n",
    "    ax[1].set_xticks(classes)\n",
    "    ax[1].set_xticklabels(xticks, rotation=30)\n",
    "    ax[1].set_xlabel('class')\n",
    "    ax[1].set_ylabel(f'FPR')\n",
    "    ax[1].set_ylim(fpr_limits)\n",
    "\n",
    "\n",
    "    ax[2].title.set_text(f'ACCURACY per class')\n",
    "    ax[2].set_xticks(classes)\n",
    "    ax[2].set_xticklabels(xticks, rotation=30)\n",
    "    ax[2].set_xlabel('class')\n",
    "    ax[2].set_ylabel(f'ACCURACY')\n",
    "    ax[2].set_ylim(acc_limits)\n",
    "\n",
    "\n",
    "    ax[3].title.set_text(f'Average detection delay per class')\n",
    "    ax[3].set_xticks(classes)\n",
    "    ax[3].set_xticklabels(xticks, rotation=30)\n",
    "    ax[3].set_xlabel('class')\n",
    "    ax[3].set_ylabel(f'Time steps')\n",
    "\n",
    "    tpr_df = pd.DataFrame()\n",
    "    fpr_df = pd.DataFrame()\n",
    "    acc_df = pd.DataFrame()\n",
    "    dd_df = pd.DataFrame()\n",
    "\n",
    "    for model in models.keys():\n",
    "\n",
    "        dd = list(models[model]['detection_delay'].values())\n",
    "\n",
    "        ax[0].plot(models[model][step]['TPR'], \n",
    "                   f\"-{models[model]['marker_style']}\",\n",
    "                   color=models[model]['marker_color'], \n",
    "                   markersize=8,\n",
    "                   label=models[model]['label'])\n",
    "\n",
    "        ax[1].plot(models[model][step]['FPR'], \n",
    "                   f\"-{models[model]['marker_style']}\",\n",
    "                   color=models[model]['marker_color'],\n",
    "                   markersize=8,\n",
    "                   label=models[model]['label'])\n",
    "\n",
    "        ax[2].plot(models[model][step]['ACCURACY'], \n",
    "                   f\"-{models[model]['marker_style']}\", \n",
    "                   color=models[model]['marker_color'],\n",
    "                   markersize=8,\n",
    "                   label=models[model]['label'])\n",
    "\n",
    "        ax[3].plot(dd, \n",
    "                   f\"-{models[model]['marker_style']}\",\n",
    "                   color=models[model]['marker_color'], \n",
    "                   markersize=8,\n",
    "                   label=models[model]['label'])\n",
    "\n",
    "        tpr_df[models[model]['label']] = models[model][step]['TPR']\n",
    "        fpr_df[models[model]['label']] = models[model][step]['FPR']\n",
    "        acc_df[models[model]['label']] = models[model][step]['ACCURACY']\n",
    "        dd_df[models[model]['label']] = dd\n",
    "\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()\n",
    "    ax[2].legend()\n",
    "    ax[3].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    fig.savefig(f\"results_{step}.png\")\n",
    "\n",
    "    tpr_df.index = xticks\n",
    "    fpr_df.index = xticks\n",
    "    acc_df.index = xticks\n",
    "    dd_df.index = xticks\n",
    "    \n",
    "    tpr_df = tpr_df[cols_order]\n",
    "    fpr_df = fpr_df[cols_order]\n",
    "    acc_df = acc_df[cols_order]\n",
    "    dd_df = dd_df[cols_order]\n",
    "    \n",
    "    return tpr_df, fpr_df, acc_df, dd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tpr_df_last, fpr_df_last, acc_df_last, dd_df_last = get_results(step=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dd_df_last.to_csv(\"dd_df_last.csv\", float_format='%.2f')\n",
    "# tpr_df_last.to_csv(\"tpr_df_last.csv\", float_format='%.2f')\n",
    "# fpr_df_last.to_csv(\"fpr_df_last.csv\", float_format='%.2f')\n",
    "# acc_df_last.to_csv(\"acc_df_last.csv\", float_format='%.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tpr_df_5, fpr_df_5, acc_df_5, dd_df_5 = get_results(step=50, tpr_limits=[0.0, 1.1], \n",
    "                                                    fpr_limits=[0, 0.1],\n",
    "                                                    acc_limits=[0.6, 1.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_df_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Model's summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_att_lstm\n",
    "model_att_gru\n",
    "model_multi_gru\n",
    "model_multi_lstm\n",
    "model_rnn_lstm\n",
    "model_rnn_gru\n",
    "model_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(model, idxs):\n",
    "\n",
    "    for i, item in enumerate(model.named_modules()):\n",
    "        print(i, item[1])\n",
    "        \n",
    "    print(\"------------------------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    for i, item in enumerate(model.named_modules()):\n",
    "        if i in idxs:\n",
    "            print(item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model_multi_gru, [1, 3, 4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model_multi_lstm, [1, 3, 4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model_rnn_gru, [0,1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model_rnn_lstm, [0,1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model_att_gru, [1,3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model_att_lstm, [1,3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "summary(model_trans, [1,3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
