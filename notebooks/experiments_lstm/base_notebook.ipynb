{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import pyreadr as py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torch.optim import Adam, RMSprop\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import datetime\n",
    "\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Data downloading\n",
    "Data link  \n",
    "https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/6C3JR1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data description\n",
    "Here we consoder dataset of \"Additional Tennessee Eastman Process Simulation Data for Anomaly Detection Evaluation\"\n",
    "This dataverse contains the data referenced in Rieth et al. (2017). Issues and Advances in Anomaly Detection Evaluation for Joint Human-Automated Systems. To be presented at Applied Human Factors and Ergonomics 2017.\n",
    "##### Columns description\n",
    "* **faultNumber** ranges from 1 to 20 in the “Faulty” datasets and represents the fault type in the TEP. The “FaultFree” datasets only contain fault 0 (i.e. normal operating conditions).\n",
    "* **simulationRun** ranges from 1 to 500 and represents a different random number generator state from which a full TEP dataset was generated (Note: the actual seeds used to generate training and testing datasets were non-overlapping).\n",
    "* **sample** ranges either from 1 to 500 (“Training” datasets) or 1 to 960 (“Testing” datasets). The TEP variables (columns 4 to 55) were sampled every 3 minutes for a total duration of 25 hours and 48 hours respectively. Note that the faults were introduced 1 and 8 hours into the Faulty Training and Faulty Testing datasets, respectively.\n",
    "* **columns 4-55** contain the process variables; the column names retain the original variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! unzip ../../data/raw/dataverse_files.zip -d ../../data/raw/dataverse_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading train data in .R format\n",
    "a1 = py.read_r(\"../../data/raw/dataverse_files/TEP_FaultFree_Training.RData\")\n",
    "a2 = py.read_r(\"../../data/raw/dataverse_files/TEP_Faulty_Training.RData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objects that are present in a1 : odict_keys(['fault_free_training'])\n",
      "Objects that are present in a2 : odict_keys(['faulty_training'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Objects that are present in a1 :\", a1.keys())\n",
    "print(\"Objects that are present in a2 :\", a2.keys())\n",
    "# print(\"Objects that are present in a3 :\", a3.keys())\n",
    "# print(\"Objects that are present in a4 :\", a4.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatinating the train and the test dataset\n",
    "\n",
    "raw_train = pd.concat([a1['fault_free_training'], a2['faulty_training']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5250000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.250.000, 10.080.000\n",
    "len(raw_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "        'xmeas_1', 'xmeas_2', 'xmeas_3', 'xmeas_4', 'xmeas_5', 'xmeas_6', 'xmeas_7', 'xmeas_8',\n",
    "        'xmeas_9', 'xmeas_10', 'xmeas_11', 'xmeas_12', 'xmeas_13', 'xmeas_14', 'xmeas_15', 'xmeas_16', \n",
    "        'xmeas_17', 'xmeas_18', 'xmeas_19', 'xmeas_20', 'xmeas_21', 'xmeas_22', 'xmeas_23', 'xmeas_24', \n",
    "        'xmeas_25', 'xmeas_26', 'xmeas_27', 'xmeas_28', 'xmeas_29', 'xmeas_30', 'xmeas_31', 'xmeas_32',\n",
    "        'xmeas_33', 'xmeas_34', 'xmeas_35', 'xmeas_36', 'xmeas_37', 'xmeas_38', 'xmeas_39', 'xmeas_40', \n",
    "        'xmeas_41', 'xmv_1', 'xmv_2', 'xmv_3', 'xmv_4', 'xmv_5', 'xmv_6', 'xmv_7', 'xmv_8', 'xmv_9', \n",
    "        'xmv_10', 'xmv_11'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train['index'] = raw_train['faultNumber'] * 500 + raw_train['simulationRun'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_idx = raw_train[['index', 'faultNumber']].drop_duplicates()\n",
    "\n",
    "X_train_idx, X_val_idx = train_test_split(simulation_idx['index'], \n",
    "                                          stratify=simulation_idx['faultNumber'],\n",
    "                                          test_size=0.2, \n",
    "                                          random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = raw_train[raw_train['index'].isin(X_train_idx)].drop('index', axis=1)\n",
    "X_val = raw_train[raw_train['index'].isin(X_val_idx)].drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[features])\n",
    "\n",
    "X_train[features] = scaler.transform(X_train[features])\n",
    "X_val[features] = scaler.transform(X_val[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(y_pred, target):\n",
    "    \n",
    "    y_pred = torch.softmax(y_pred, dim=1)\n",
    "    y_pred = torch.max(y_pred, dim=1)[1]  \n",
    "    \n",
    "    return torch.eq(y_pred, target).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAULT_START_TRAINVAL = 20\n",
    "FAULT_START_TEST = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTEP(Dataset):\n",
    "\n",
    "    def __init__(self, X):\n",
    "    \n",
    "        self.X = X\n",
    "        self.X = self.X.sort_values(['faultNumber', 'simulationRun', 'sample'])\n",
    "        self.X['index'] = self.X.groupby(['faultNumber', 'simulationRun']).ngroup()\n",
    "        self.X = self.X.set_index('index')\n",
    "        \n",
    "        self.max_length = self.X['sample'].max()\n",
    "\n",
    "        self.s_list = [FAULT_START_TRAINVAL, FAULT_START_TRAINVAL + 200]\n",
    "        self.l_list = [5, 25, 50, 100, 250]\n",
    "        \n",
    "#         self.s_list = [FAULT_START_TRAINVAL]\n",
    "#         self.l_list = [50, 100]\n",
    "        \n",
    "        self.features = [\n",
    "                'xmeas_1', 'xmeas_2', 'xmeas_3', 'xmeas_4', 'xmeas_5', 'xmeas_6', 'xmeas_7', 'xmeas_8', 'xmeas_9', \n",
    "                'xmeas_10', 'xmeas_11', 'xmeas_12', 'xmeas_13', 'xmeas_14', 'xmeas_15', 'xmeas_16', 'xmeas_17', \n",
    "                'xmeas_18', 'xmeas_19', 'xmeas_20', 'xmeas_21', 'xmeas_22', 'xmeas_23', 'xmeas_24', 'xmeas_25', \n",
    "                'xmeas_26', 'xmeas_27', 'xmeas_28', 'xmeas_29', 'xmeas_30', 'xmeas_31', 'xmeas_32', 'xmeas_33', \n",
    "                'xmeas_34', 'xmeas_35', 'xmeas_36', 'xmeas_37', 'xmeas_38', 'xmeas_39', 'xmeas_40', 'xmeas_41', \n",
    "                'xmv_1', 'xmv_2', 'xmv_3', 'xmv_4', 'xmv_5', 'xmv_6', 'xmv_7', 'xmv_8', 'xmv_9', 'xmv_10', 'xmv_11'\n",
    "            ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.index.nunique() * len(self.s_list) * len(self.l_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        fault_sim_idx = idx // (len(self.s_list) * len(self.l_list))\n",
    "    \n",
    "        start_length_idxs = idx % (len(self.s_list) * len(self.l_list))\n",
    "        \n",
    "        start_idx = self.s_list[start_length_idxs // len(self.l_list)]\n",
    "        seq_length = self.l_list[start_length_idxs % len(self.l_list)]\n",
    "\n",
    "        features = self.X.loc[fault_sim_idx][self.features].values[start_idx : (start_idx+seq_length), :]\n",
    "        target = self.X.loc[fault_sim_idx]['faultNumber'].unique()[0]\n",
    "\n",
    "        features = torch.tensor(features, dtype=torch.float)\n",
    "        target = torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "        return features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "\n",
    "    sequences = [x[0] for x in batch]\n",
    "    labels = [x[1] for x in batch]\n",
    "        \n",
    "    lengths = torch.LongTensor([len(x) for x in sequences])\n",
    "    lengths, idx = lengths.sort(0, descending=True)\n",
    "    \n",
    "    sequences = [sequences[i] for i in idx]\n",
    "    \n",
    "    labels = torch.tensor(labels, dtype=torch.long)[idx]\n",
    "    \n",
    "    sequences_padded = pad_sequence(sequences, batch_first=True)\n",
    "\n",
    "    return sequences_padded, lengths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = DataTEP(X_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True)\n",
    "\n",
    "val_ds = DataTEP(X_val)\n",
    "val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE*4, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84000, 21000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniRNN(nn.Module) :\n",
    "    def __init__(self, RNN_TYPE, NUM_LAYERS, INPUT_SIZE, HIDDEN_SIZE, LINEAR_SIZE, OUTPUT_SIZE, BIDIRECTIONAL, DESCRIPTION):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rnn_type = RNN_TYPE\n",
    "        self.hidden_size = HIDDEN_SIZE\n",
    "        self.num_layers = NUM_LAYERS\n",
    "        self.input_size = INPUT_SIZE\n",
    "        self.linear_size = LINEAR_SIZE\n",
    "        self.output_size = OUTPUT_SIZE\n",
    "        self.bidirectional = BIDIRECTIONAL\n",
    "        self.description = DESCRIPTION\n",
    "        \n",
    "        rnn_cell = getattr(nn, RNN_TYPE)\n",
    "        \n",
    "        self.rnn = rnn_cell(\n",
    "                        input_size=self.input_size, \n",
    "                        hidden_size=self.hidden_size,\n",
    "                        num_layers=self.num_layers, \n",
    "                        bidirectional=self.bidirectional,\n",
    "                        batch_first=True,\n",
    "                        dropout=0.4\n",
    "                )    \n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "                        nn.Linear(in_features=self.hidden_size*(self.bidirectional+1), out_features=self.linear_size),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(p=0.4),\n",
    "                        nn.Linear(in_features=self.linear_size, out_features=self.output_size),\n",
    "                )\n",
    "    \n",
    "    def get_params(self):\n",
    "        \n",
    "        return {\n",
    "            \"RNN_TYPE\": self.rnn_type,\n",
    "            \"HIDDEN_SIZE\": self.hidden_size,\n",
    "            \"NUM_LAYERS\": self.num_layers,\n",
    "            \"INPUT_SIZE\": self.input_size,\n",
    "            \"LINEAR_SIZE\": self.linear_size,\n",
    "            \"OUTPUT_SIZE\": self.output_size,\n",
    "            \"BIDIRECTIONAL\": self.bidirectional,\n",
    "            \"DESCRIPTION\": self.description,\n",
    "            }\n",
    "            \n",
    "    def forward(self, x, x_length):\n",
    "        \n",
    "        x_packed = pack_padded_sequence(x, x_length, batch_first=True)\n",
    "        x_rnn_out, _ = self.rnn(x_packed)\n",
    "        x_unpacked, _ = pad_packed_sequence(x_rnn_out, batch_first=True)\n",
    "        \n",
    "        idx_last_hidden = (x_length - 1).view(-1, 1).expand(len(x_length), x_unpacked.size(2)).unsqueeze(1)\n",
    "        idx_last_hidden = idx_last_hidden.to(x.device)\n",
    "        x_last_hiddens = x_unpacked.gather(1, idx_last_hidden).squeeze(1)\n",
    "        \n",
    "        x = self.head(x_last_hiddens)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModel(torch.nn.Module):\n",
    "    def __init__(self, RNN_TYPE, NUM_LAYERS, INPUT_SIZE, HIDDEN_SIZE, LINEAR_SIZE, OUTPUT_SIZE, BIDIRECTIONAL):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.rnn_type = RNN_TYPE\n",
    "        self.hidden_size = HIDDEN_SIZE\n",
    "        self.num_layers = NUM_LAYERS\n",
    "        self.input_size = INPUT_SIZE\n",
    "        self.linear_size = LINEAR_SIZE\n",
    "        self.output_size = OUTPUT_SIZE\n",
    "        self.bidirectional = BIDIRECTIONAL\n",
    "        \n",
    "        rnn_cell = getattr(nn, RNN_TYPE)\n",
    "\n",
    "        self.rnn = rnn_cell(\n",
    "                        input_size=self.input_size, \n",
    "                        hidden_size=self.hidden_size, \n",
    "                        num_layers=self.num_layers, \n",
    "                        bidirectional=self.bidirectional,\n",
    "                        dropout=0.4,\n",
    "                        batch_first=True\n",
    "                )\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "#                         nn.Linear(in_features=self.hidden_size*(self.bidirectional+1), out_features=self.output_size),\n",
    "                        nn.Linear(in_features=self.hidden_size*(self.bidirectional+1), out_features=self.linear_size),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(p=0.4),\n",
    "                        nn.Linear(in_features=self.linear_size, out_features=self.output_size),\n",
    "                )\n",
    "        \n",
    "        \n",
    "    def get_params(self):\n",
    "        \n",
    "        return {\n",
    "            \"RNN_TYPE\": self.rnn_type, \n",
    "            \"HIDDEN_SIZE\": self.hidden_size,\n",
    "            \"NUM_LAYERS\": self.num_layers,\n",
    "            \"INPUT_SIZE\": self.input_size,\n",
    "            \"LINEAR_SIZE\": self.linear_size,\n",
    "            \"OUTPUT_SIZE\": self.output_size,\n",
    "            \"BIDIRECTIONAL\": self.bidirectional\n",
    "        }\n",
    "    \n",
    "\n",
    "    def attention(self, lstm_output, last_hidden):\n",
    "        \n",
    "        attn_weights = torch.bmm(lstm_output, last_hidden.unsqueeze(2)).squeeze(2)\n",
    "        soft_attn_weights = F.softmax(attn_weights, dim=1)\n",
    "        new_hidden_state = torch.bmm(lstm_output.transpose(1, 2), soft_attn_weights.unsqueeze(2)).squeeze(2)\n",
    "\n",
    "        return new_hidden_state\n",
    "    \n",
    "    def forward(self, x, x_length):\n",
    "\n",
    "        x_packed = pack_padded_sequence(x, x_length, batch_first=True)\n",
    "        \n",
    "        x_rnn_out, _ = self.rnn(x_packed)\n",
    "        \n",
    "        x_unpacked, __ = pad_packed_sequence(x_rnn_out, batch_first=True)\n",
    "        \n",
    "        idx_last_hidden = (x_length - 1).view(-1, 1).expand(len(x_length), x_unpacked.size(2)).unsqueeze(1)\n",
    "        idx_last_hidden = idx_last_hidden.to(x.device)\n",
    "        x_last_hiddens = x_unpacked.gather(1, idx_last_hidden).squeeze(1)\n",
    "        \n",
    "        attention_out = self.attention(x_unpacked, x_last_hiddens)\n",
    "        x = self.head(attention_out)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(torch.nn.Module):\n",
    "    def __init__(self, NUM_LAYERS, INPUT_SIZE, HIDDEN_SIZE, LINEAR_SIZE, OUTPUT_SIZE, DROPOUT):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = HIDDEN_SIZE\n",
    "        self.num_layers = NUM_LAYERS\n",
    "        self.input_size = INPUT_SIZE\n",
    "        self.linear_size = LINEAR_SIZE\n",
    "        self.output_size = OUTPUT_SIZE\n",
    "        self.dropout = DROPOUT\n",
    "        \n",
    "        transformer_encoder_layer = nn.TransformerEncoderLayer(\n",
    "                        d_model=self.input_size, \n",
    "                        nhead=4, \n",
    "                        dim_feedforward=self.hidden_size, \n",
    "                        dropout=self.dropout, \n",
    "                        activation='relu'\n",
    "                )\n",
    "        \n",
    "        \n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "                        encoder_layer=transformer_encoder_layer, \n",
    "                        num_layers=self.num_layers, \n",
    "                        norm=None\n",
    "                )\n",
    "        \n",
    "        self.weighted_mean = nn.Conv1d(\n",
    "                        in_channels=self.input_size, \n",
    "                        out_channels=self.input_size, \n",
    "                        kernel_size=100, \n",
    "                        groups=self.input_size)\n",
    "    \n",
    "        self.head = nn.Sequential(\n",
    "                        nn.Dropout(p=0.2),\n",
    "                        nn.Linear(in_features=52, out_features=self.output_size),\n",
    "#                         nn.Linear(in_features=52, out_features=self.linear_size),\n",
    "#                         nn.ReLU(),\n",
    "#                         nn.Dropout(p=0.4),\n",
    "#                         nn.Linear(in_features=self.linear_size, out_features=self.output_size),\n",
    "                )\n",
    "        \n",
    "    \n",
    "    def get_params(self):\n",
    "        \n",
    "        return {\n",
    "                \"HIDDEN_SIZE\": self.hidden_size,\n",
    "                \"NUM_LAYERS\": self.num_layers,\n",
    "                \"INPUT_SIZE\": self.input_size,\n",
    "                \"LINEAR_SIZE\": self.linear_size,\n",
    "                \"OUTPUT_SIZE\": self.output_size,\n",
    "                \"DROPOUT\": self.dropout\n",
    "            }    \n",
    "    \n",
    "    \n",
    "    def forward(self, x, x_length=None):\n",
    "        \"\"\"\n",
    "        src: (S, N, E) = (sequence_length, batch_size, n_features)\n",
    "        src_key_padding_mask: (N, S) = (batch_size, sequence_length)\n",
    "        \"\"\"\n",
    "    \n",
    "        x_mask = torch.zeros(x.size(0), x.size(1), dtype=bool, device=x.device)\n",
    "        \n",
    "        for i in range(len(x)):\n",
    "            x_mask[i, x_length[i]:] = True\n",
    "\n",
    "        x = self.transformer_encoder(src=x.transpose(0, 1), src_key_padding_mask=x_mask)\n",
    "        x = x.permute(1, 2, 0)\n",
    "        x = self.weighted_mean(x)\n",
    "        x = x.squeeze(-1)\n",
    "        x = self.head(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "NUM_LAYERS = 2\n",
    "HIDDEN_SIZE = 128\n",
    "LINEAR_SIZE = 64\n",
    "BIDIRECTIONAL = True\n",
    "\n",
    "RNN_TYPE = \"LSTM\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "model = UniRNN(\n",
    "            RNN_TYPE=RNN_TYPE, NUM_LAYERS=NUM_LAYERS, INPUT_SIZE=52, HIDDEN_SIZE=HIDDEN_SIZE, \n",
    "            LINEAR_SIZE=LINEAR_SIZE, OUTPUT_SIZE=NUM_CLASSES, BIDIRECTIONAL=BIDIRECTIONAL, \n",
    "            DESCRIPTION='simple_model_for_metrics'\n",
    "        )\n",
    "\n",
    "# model = AttentionModel(\n",
    "#             RNN_TYPE=RNN_TYPE, NUM_LAYERS=NUM_LAYERS, INPUT_SIZE=52, HIDDEN_SIZE=HIDDEN_SIZE, \n",
    "#             LINEAR_SIZE=LINEAR_SIZE, OUTPUT_SIZE=NUM_CLASSES, BIDIRECTIONAL=BIDIRECTIONAL\n",
    "#         )\n",
    "\n",
    "# model = TransformerModel(\n",
    "#             NUM_LAYERS=6, INPUT_SIZE=52, HIDDEN_SIZE=128, LINEAR_SIZE=52, OUTPUT_SIZE=21, DROPOUT=0.4\n",
    "#         )\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# scheduler = StepLR(optimizer, step_size=25, gamma=0.5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, patience=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "64 64 64\n",
      "tensor([250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 100, 100, 100, 100,\n",
      "        100, 100, 100,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5])\n",
      "y_batch_train.size() torch.Size([64])\n",
      "y_pred_train.size() torch.Size([64, 21]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (X_batch, X_lengths, y_batch) in enumerate(train_dl):\n",
    "    if i < 1:\n",
    "        print(type(X_batch), type(X_lengths), type(y_batch))\n",
    "        print(len(X_batch), len(X_lengths), len(y_batch))\n",
    "        print(X_lengths)\n",
    "        X_batch, y_batch_train = X_batch.to(device), y_batch.to(device)\n",
    "        y_pred_train = model(X_batch, X_lengths)\n",
    "        print(\"y_batch_train.size()\", y_batch.size())\n",
    "        print(\"y_pred_train.size()\", y_pred_train.size(), '\\n')\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f\"final_models/rnn/{RNN_TYPE}_{datetime.today().strftime('%d%b-%H-%M')}\"\n",
    "\n",
    "writer = SummaryWriter(log_dir=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mGRU_22May-14-24\u001b[0m/  \u001b[01;34mLSTM_22May-20-05\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls final_models/rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2cdc7c0b1b430b8baa0566084ad09f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0acdbc207c654875967dea9ec872b354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 312.70656538009644\n",
      "mean loss train: 1.200728357383183, mean loss val: 0.8062644958155496\n",
      "accuracy train: 0.5961547619047619, accuracy val: 0.7092380952380952\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 1, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6403b9dd54414637a8b8ce1ea3ce4447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf67182776974b29af7dd621080e66b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 309.7578022480011\n",
      "mean loss train: 0.8037863115810213, mean loss val: 0.6849802811543146\n",
      "accuracy train: 0.7069285714285715, accuracy val: 0.7331428571428571\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 2, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319dbfcc3ee247c59e21dce47c45a1c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80921c8cf0614c13a4fabe738654271a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 327.5970163345337\n",
      "mean loss train: 0.6917781223342532, mean loss val: 0.6455504363264356\n",
      "accuracy train: 0.7350595238095238, accuracy val: 0.7412380952380953\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 3, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f4bcf5b9034ca4a7008cf407354f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f67fa0a8abf452b9c0f323bc7aec7c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 308.1533946990967\n",
      "mean loss train: 0.6239390848931812, mean loss val: 0.5665721411705017\n",
      "accuracy train: 0.7615952380952381, accuracy val: 0.7870952380952381\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 4, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa18465d1054f9da17302fe003069fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1bc847c193646adadb8ecfb8104c94a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 298.19315457344055\n",
      "mean loss train: 0.5697268995671045, mean loss val: 0.5269889536812192\n",
      "accuracy train: 0.7881904761904762, accuracy val: 0.7952857142857143\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 5, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5ad6494e04445bbaa76cec77face11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e818e19afd7a4ef2a61436d83cb241ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 304.39375019073486\n",
      "mean loss train: 0.5174770648933592, mean loss val: 0.4631168573697408\n",
      "accuracy train: 0.8065952380952381, accuracy val: 0.8273809523809523\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 6, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c9950400e64c51a3afa8a51aa98f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6ca2bcd08047359ec0d78aa4ab5c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 303.2604994773865\n",
      "mean loss train: 0.48372297762689137, mean loss val: 0.4561577461560567\n",
      "accuracy train: 0.8205357142857143, accuracy val: 0.827952380952381\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 7, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2b2e6e7ff34ed2b62ebe9ddee2e56e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5e2fdef4d04468b90891d3d3044bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 301.8135187625885\n",
      "mean loss train: 0.45129255350714637, mean loss val: 0.39870276403427124\n",
      "accuracy train: 0.8351785714285714, accuracy val: 0.852\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 8, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc20e61d04b41f2b2b9be52762d4500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12448717c4e6402681595baa030e7801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 329.7265088558197\n",
      "mean loss train: 0.4161474258388792, mean loss val: 0.38065150551568894\n",
      "accuracy train: 0.8457738095238095, accuracy val: 0.8544285714285714\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 9, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1bdbc31e16f4132972e2fac5a56f659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa961187318147ecb7d1b95aa1e52184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 378.5275945663452\n",
      "mean loss train: 0.39688490252267744, mean loss val: 0.4260192229520707\n",
      "accuracy train: 0.8527023809523809, accuracy val: 0.8448095238095238\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 10, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10d2c7d6f3048b2b806635379b3ac27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae179f089b2a4524bfbfc9bf75693bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 379.4460828304291\n",
      "mean loss train: 0.392730537596203, mean loss val: 0.40950301248686655\n",
      "accuracy train: 0.8531547619047619, accuracy val: 0.8511904761904762\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 11, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d37bf4668384a4a9895d4ea13de82aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cadeb94c9cb4039a24ddc6647c3b0df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 377.0882656574249\n",
      "mean loss train: 0.380492652790887, mean loss val: 0.3775323745409648\n",
      "accuracy train: 0.8563928571428572, accuracy val: 0.857\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 12, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09198afac62e4b91b6234a979c291707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cec4bf51d0240d7895be48bd0e836bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 379.9634201526642\n",
      "mean loss train: 0.36062960667837235, mean loss val: 0.3606046280747368\n",
      "accuracy train: 0.8605238095238095, accuracy val: 0.8602857142857143\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 13, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0c3b346a7842c7b90deb95647d05ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a1a9e30a284619b829d5f51e3ab5f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 318.51845240592957\n",
      "mean loss train: 0.35363493607157753, mean loss val: 0.3595823747827893\n",
      "accuracy train: 0.8620952380952381, accuracy val: 0.8620952380952381\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 14, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0094e5e161224dae9a81a460b035250a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f90b960d3dd4f78ade0876fd0cf5994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 322.73404479026794\n",
      "mean loss train: 0.37685223522072747, mean loss val: 0.3600970147450765\n",
      "accuracy train: 0.8559404761904762, accuracy val: 0.8614285714285714\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 15, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa81d04e7d24f25ac10aa651bb680cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62172695f5b94f9ebf72a4acd2eaea40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 306.0736892223358\n",
      "mean loss train: 0.3516054299672445, mean loss val: 0.3594141478311448\n",
      "accuracy train: 0.8635, accuracy val: 0.8611428571428571\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 16, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea42dac3e6d4eb5adaf4d89b607d948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d3720959d6492e93762c2861c390fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 319.46883392333984\n",
      "mean loss train: 0.343351718885558, mean loss val: 0.3388568589573815\n",
      "accuracy train: 0.8647976190476191, accuracy val: 0.8665238095238095\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 17, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9289cf13fe49378558675a44a36283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b1433413a743a8985e313451b3044b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 331.23977637290955\n",
      "mean loss train: 0.33815325106325606, mean loss val: 0.3474018825122288\n",
      "accuracy train: 0.866702380952381, accuracy val: 0.8633333333333333\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 18, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d63f5c21ee4729b359748d0982c2e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0225973750e452eb86f90e787d40223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 386.47868299484253\n",
      "mean loss train: 0.33222874316715056, mean loss val: 0.40572164107504344\n",
      "accuracy train: 0.86725, accuracy val: 0.8497619047619047\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 19, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b78ca2a583743d08defcb5694100824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b4e4f9468d45d5811b17d34fd948d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 377.2668573856354\n",
      "mean loss train: 0.32854787216016224, mean loss val: 0.3440535592578706\n",
      "accuracy train: 0.8691428571428571, accuracy val: 0.8648095238095238\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 20, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29634e0932ce491c957694543de097c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c0825f33a4c44ef8b016a095fa9f823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 372.49325728416443\n",
      "mean loss train: 0.3284746265751975, mean loss val: 0.3505087535040719\n",
      "accuracy train: 0.8695119047619048, accuracy val: 0.8647142857142858\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 21, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb07c73f6d34dc6b28c5f4dc213cd45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea9da4e207264421849fe73f30767792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 376.58921360969543\n",
      "mean loss train: 0.3199148303781237, mean loss val: 0.34145523351714724\n",
      "accuracy train: 0.8708928571428571, accuracy val: 0.8646666666666667\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 22, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb98f5f3e5643d780af6240ca02d016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13de4d14fa9445a8af25b98f76010f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 391.7393755912781\n",
      "mean loss train: 0.3243910070090067, mean loss val: 0.35933047138509294\n",
      "accuracy train: 0.8706547619047619, accuracy val: 0.8619523809523809\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 23, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06899f321aeb45fd956e139ba0da97a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4053ae43728b4fa7980b81d14a918a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 375.30518794059753\n",
      "mean loss train: 0.3132556274391356, mean loss val: 0.3358030377512886\n",
      "accuracy train: 0.8720476190476191, accuracy val: 0.8660476190476191\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 24, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a7c09f4b574502bd07b81854c435fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9613d0bc03b04217b6c5e72ee7fd41bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14af94c3aae34f8e80ea65634653daad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 376.5064444541931\n",
      "mean loss train: 0.30967776268720626, mean loss val: 0.3534756637527829\n",
      "accuracy train: 0.8732619047619048, accuracy val: 0.8631904761904762\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 26, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d20ea7cfa4f24f2d92efc6d024cad052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3694681e153c4c1eae87ed4c8d27eecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 373.18240571022034\n",
      "mean loss train: 0.30351681162629807, mean loss val: 0.3536099841594696\n",
      "accuracy train: 0.8759523809523809, accuracy val: 0.8664761904761905\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 28, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bffa992e8624ce79ca6764c05f08d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 380.56754970550537\n",
      "mean loss train: 0.3001031579630716, mean loss val: 0.34485089669908797\n",
      "accuracy train: 0.8761904761904762, accuracy val: 0.8622857142857143\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 30, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f923039f5e54a4e9cb0287e57b61208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3864168a92e44810853dddc4a86a0824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 384.51441049575806\n",
      "mean loss train: 0.2951418293828056, mean loss val: 0.34689281784920467\n",
      "accuracy train: 0.876702380952381, accuracy val: 0.8641428571428571\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 31, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3c1df95dbe490f9edfddc9e9fff7ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe12a3e346d46448ce5b0401de7f226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 384.7128233909607\n",
      "mean loss train: 0.2926755879748435, mean loss val: 0.3627801137878781\n",
      "accuracy train: 0.8787857142857143, accuracy val: 0.8625714285714285\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 33, Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbcdd92683734b939e736e413279042d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a530e5e86344599b835a3f6da9cbe1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 382.7468001842499\n",
      "mean loss train: 0.2667906756571361, mean loss val: 0.32851337778000606\n",
      "accuracy train: 0.8852380952380953, accuracy val: 0.8693809523809524\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 36, Learning Rate: 0.0001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66a590574644d19a3dd04cf369c60b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed9053c2c7a4871a7df213581577813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 382.4492530822754\n",
      "mean loss train: 0.2598676007872536, mean loss val: 0.3295431426706768\n",
      "accuracy train: 0.8876428571428572, accuracy val: 0.8691904761904762\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 38, Learning Rate: 0.0001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b54d5304ea4104b33571f534fd1e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4329c8237b8a4fc68262e2b302f9ed99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 379.3573098182678\n",
      "mean loss train: 0.2541881199166888, mean loss val: 0.3391326878070831\n",
      "accuracy train: 0.8897738095238096, accuracy val: 0.8694285714285714\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 41, Learning Rate: 0.0001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2327a4fa8be341b6ba2d3f6d7e405620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 373.00062346458435\n",
      "mean loss train: 0.2516521764369238, mean loss val: 0.33839902865319027\n",
      "accuracy train: 0.891547619047619, accuracy val: 0.8693809523809524\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 43, Learning Rate: 0.0001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a6c391a4c54b888e59560d7e3c3a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5750322a036340f29f79669b4985d37f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8fa6fae0404e6ab9d4baa10abba28c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 308.51698875427246\n",
      "mean loss train: 0.2498565129779634, mean loss val: 0.34270754991542723\n",
      "accuracy train: 0.8942023809523809, accuracy val: 0.8708095238095238\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 46, Learning Rate: 0.0001\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a47bd0fc52406c984beb150b888024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae250b1a6344e6d8208559aedfcef35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch time: 299.09687900543213\n",
      "mean loss train: 0.24522449035729682, mean loss val: 0.34671375720841546\n",
      "accuracy train: 0.8979166666666667, accuracy val: 0.8704761904761905\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch: 49, Learning Rate: 1e-05\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1839a2aa9ed5401eb7a865b7b2d17389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_train_all, loss_val_all = [], []\n",
    "accuracy_train_all, accuracy_val_all = [], []\n",
    "\n",
    "best_model_acc = 0\n",
    "best_model_epoch = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    start = time.time()\n",
    "    print(f\"Epoch: {epoch}, Learning Rate: {optimizer.param_groups[0]['lr']}\\n\")\n",
    "\n",
    "    loss_train_epoch, loss_val_epoch = 0, 0\n",
    "    correct_train_epoch, correct_val_epoch = 0, 0\n",
    "    n_train, n_val = 0, 0\n",
    "\n",
    "    model.train()\n",
    "    for (X_batch_train, X_batch_lengths_train, y_batch_train) in tqdm(train_dl):\n",
    "\n",
    "        X_batch_train, X_batch_lengths_train, y_batch_train =\\\n",
    "                    X_batch_train.to(device), X_batch_lengths_train.to(device), y_batch_train.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred_train = model(X_batch_train, X_batch_lengths_train)\n",
    "        loss_train = criterion(y_pred_train, y_batch_train)\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train_epoch += loss_train.item() * y_batch_train.size()[0]\n",
    "        correct_train_epoch += correct(y_pred_train, y_batch_train)\n",
    "        n_train += y_batch_train.size()[0]\n",
    "\n",
    "#     scheduler.step()\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for (X_batch_val, X_batch_lengths_val, y_batch_val) in tqdm(val_dl):\n",
    "\n",
    "            X_batch_val, X_batch_lengths_val, y_batch_val =\\\n",
    "                    X_batch_val.to(device), X_batch_lengths_val.to(device), y_batch_val.to(device)\n",
    "\n",
    "            y_pred_val = model(X_batch_val, X_batch_lengths_val)\n",
    "            loss_val = criterion(y_pred_val, y_batch_val)\n",
    "            \n",
    "            loss_val_epoch += loss_val.item() * y_batch_val.size()[0]\n",
    "            correct_val_epoch += correct(y_pred_val, y_batch_val)\n",
    "            n_val += y_batch_val.size()[0]\n",
    "            \n",
    "    loss_mean_train_epoch = loss_train_epoch / n_train\n",
    "    loss_mean_val_epoch = loss_val_epoch / n_val\n",
    "\n",
    "    loss_train_all.append(loss_mean_train_epoch)\n",
    "    loss_val_all.append(loss_mean_val_epoch)\n",
    "\n",
    "    accuracy_train_epoch = correct_train_epoch / n_train\n",
    "    accuracy_val_epoch = correct_val_epoch / n_val\n",
    "\n",
    "    accuracy_train_all.append(accuracy_train_epoch)\n",
    "    accuracy_val_all.append(accuracy_val_epoch)\n",
    "\n",
    "    writer.add_scalars('LOSS per epoch', {\"train\": loss_mean_train_epoch, \"val\": loss_mean_val_epoch}, epoch)\n",
    "    writer.add_scalars('ACCURACY per epoch', {\"train\": accuracy_train_epoch, \"val\": accuracy_val_epoch}, epoch)\n",
    "    \n",
    "    if accuracy_val_epoch > best_model_acc:\n",
    "        \n",
    "        best_model_state_dict = model.state_dict()\n",
    "        best_model_acc = accuracy_val_epoch\n",
    "        best_model_epoch = epoch\n",
    "        \n",
    "    scheduler.step(loss_mean_val_epoch)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f\"epoch time: {end - start}\")  \n",
    "    print(f\"mean loss train: {loss_mean_train_epoch}, mean loss val: {loss_mean_val_epoch}\")\n",
    "    print(f\"accuracy train: {accuracy_train_epoch}, accuracy val: {accuracy_val_epoch}\")\n",
    "\n",
    "    print(\"---------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_hparams(model.get_params(), {\"best_accuracy\": best_model_acc, \"best_model_epoch\": best_model_epoch})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Loading best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_name.replace(\"final_models/\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rnn/LSTM_22May-20-05'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU_22May-14-24.pth  LSTM_22May-20-05.pth\r\n"
     ]
    }
   ],
   "source": [
    "! ls final_saved_models/rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'model': model.__class__.__name__, \n",
    "              'params': model.get_params(),\n",
    "              'state_dict': best_model_state_dict}\n",
    "\n",
    "torch.save(checkpoint, f\"final_saved_models/{model_name}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention  multi_rnn  rnn\r\n"
     ]
    }
   ],
   "source": [
    "! ls final_saved_models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UniRNN(\n",
       "  (rnn): LSTM(52, 128, num_layers=2, batch_first=True, dropout=0.4, bidirectional=True)\n",
       "  (head): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=21, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(f\"final_saved_models/{model_name}.pth\")\n",
    "\n",
    "model = getattr(sys.modules[__name__], checkpoint['model'])(**checkpoint['params'])\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "        \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Val evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates TPR, FPR and ACCURACY per class for multiple simulation runs\n",
    "    https://stackoverflow.com/questions/50666091/true-positive-rate-and-false-positive-rate-tpr-fpr-for-multi-class-data-in-py\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : \n",
    "        type: np.array \n",
    "        shape : (number of simulation runs)\n",
    "        description: true classes for simulation runs\n",
    "    \n",
    "    y_pred : np.array\n",
    "    \n",
    "        type: np.array \n",
    "        shape : (number of simulation runs)\n",
    "        description: predicted classes for simulation runs\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    TPR : \n",
    "        type: list of floats\n",
    "        shape: (number of classes)\n",
    "        description: True Positive Rate per class\n",
    "    FPR : \n",
    "        type: list of floats\n",
    "        shape: (number of classes)\n",
    "        description: False Positive Rate per class\n",
    "    ACCURACY : \n",
    "        type: list of floats\n",
    "        shape: (number of classes)\n",
    "        description: Accuracy \"one vs all\" per class\n",
    "    \"\"\"\n",
    "    \n",
    "    conf = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    FP = conf.sum(axis=0) - np.diag(conf)\n",
    "    FN = conf.sum(axis=1) - np.diag(conf)\n",
    "    TP = np.diag(conf)\n",
    "    TN = conf.sum() - (FP + FN + TP)\n",
    "    \n",
    "    TPR = TP / (TP + FN)\n",
    "    FPR = FP / (FP + TN)\n",
    "\n",
    "    ACCURACY = (TP + TN) / (TP + TN + FP + FN)\n",
    "    \n",
    "    return TPR, FPR, ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_true_idx(arr):\n",
    "    idx = np.where(arr == True)[0]\n",
    "    if len(idx) == 0:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return idx.min()\n",
    "\n",
    "def get_detection_delay(y_true, y_pred) -> dict():\n",
    "    \"\"\"\n",
    "    Calculates detection delay for every simulation run\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : \n",
    "        type : np.array \n",
    "        shape : (number of simulation runs)\n",
    "        description : true classes for simulation runs\n",
    "    \n",
    "    y_pred : np.array \n",
    "        type : np.array \n",
    "        shape : (number of simulation runs, simulation runs' lengths)\n",
    "        description: predicted classes for every sample for every simulation runs\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    detection_delay :\n",
    "        type : dict\n",
    "        keys : classes from 0 to 20\n",
    "        description : dict of detection delays for every class, nan means true class wasn't predicted\n",
    "    \n",
    "    Commentary:\n",
    "        If you want to get avarage detection delays per class, you need to calulate avg of detection_delay[key]\n",
    "        for every key \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    detection_delay = defaultdict(list)\n",
    "    \n",
    "    correct = y_pred == y_true[..., np.newaxis]\n",
    "    first_true_idxs = np.apply_along_axis(func1d=get_first_true_idx, arr=correct, axis=1)\n",
    "\n",
    "    for (cls, idx) in zip(y_true, first_true_idxs):\n",
    "        detection_delay[cls].append(idx)\n",
    "    return detection_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "y_ans_val, y_true_val = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for (X_batch_val, X_batch_lengths_val, y_batch_val) in tqdm(val_dl):\n",
    "\n",
    "        X_batch_val, X_batch_lengths_val, y_batch_val =\\\n",
    "                    X_batch_val.to(device), X_batch_lengths_val.to(device), y_batch_val.to(device)\n",
    "\n",
    "        y_pred_val = model(X_batch_val, X_batch_lengths_val)\n",
    "        \n",
    "        y_pred_prob = F.softmax(y_pred_val.cpu(), dim=-1)\n",
    "        y_pred_class = y_pred_prob.max(dim=-1)[1]\n",
    "       \n",
    "        y_ans_val += y_pred_class.tolist()\n",
    "        y_true_val += y_batch_val.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 8))\n",
    "# plt.title(\"loss\")\n",
    "# plt.plot(np.arange(len(loss_train_all)), loss_train_all, '-o', marker='.', label='train')\n",
    "# plt.plot(np.arange(len(loss_val_all)), loss_val_all, '-o', marker='.', label='val')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 8))\n",
    "# plt.title(\"accuracy\")\n",
    "# plt.plot(np.arange(len(accuracy_train_all)), accuracy_train_all, '-o', marker='.', label='train')\n",
    "# plt.plot(np.arange(len(accuracy_val_all)), accuracy_val_all, '-o', marker='.', label='val')\n",
    "# plt.text(35, 0.65, s=f\"best acc: {best_model_acc}\\nbest epoch: {best_model_epoch}\", fontsize=20)\n",
    "# plt.scatter(best_model_epoch, best_model_acc, c='g', s=100)\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.title(\"FDR\")\n",
    "sns.heatmap(confusion_matrix(y_true_val, y_ans_val, normalize='pred'), annot=True, cmap=sns.cm.rocket_r)\n",
    "plt.xlabel('predicted class')\n",
    "plt.ylabel('true class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPR, FPR, ACCURACY = get_metrics(y_true_val, y_ans_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting(arr, name, forward=True):\n",
    "    classes = np.arange(len(arr))\n",
    "\n",
    "    norm = plt.Normalize(arr.min(), arr.max())\n",
    "    \n",
    "    if forward:\n",
    "        colors = plt.cm.RdYlGn(norm(arr))\n",
    "    else:\n",
    "        colors = plt.cm.summer(norm(arr))\n",
    "        \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.title(f'{name} per class')\n",
    "#     sns.barplot(x=classes, y=arr, palette=colors)\n",
    "    plt.plot(arr, '-*', color='yellowgreen')\n",
    "    plt.xticks(classes, [\"fault_\" + str(c) if c > 0 else \"normal\" for c in classes], rotation=90)\n",
    "    plt.xlabel('class')\n",
    "    plt.ylabel(f'{name}')\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting(TPR, \"TPR (true positive rate)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting(FPR, \"FPR (false positive rate)\", forward=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting(ACCURACY, \"ACCURACY vs ALL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Test evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading test data in .R format\n",
    "a3 = py.read_r(\"../../data/raw/dataverse_files/TEP_FaultFree_Testing.RData\")\n",
    "a4 = py.read_r(\"../../data/raw/dataverse_files/TEP_Faulty_Testing.RData\")\n",
    "\n",
    "raw_test = pd.concat([a3['fault_free_testing'], a4['faulty_testing']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test[features] = scaler.transform(raw_test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test['index'] = raw_test['faultNumber'] * 500 + raw_test['simulationRun'] - 1\n",
    "raw_test = raw_test.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTEST(Dataset):\n",
    "\n",
    "    def __init__(self, X, seq_length):\n",
    "    \n",
    "        self.X = X\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        self.features = [\n",
    "                'xmeas_1', 'xmeas_2', 'xmeas_3', 'xmeas_4', 'xmeas_5', 'xmeas_6', 'xmeas_7', 'xmeas_8', 'xmeas_9', \n",
    "                'xmeas_10', 'xmeas_11', 'xmeas_12', 'xmeas_13', 'xmeas_14', 'xmeas_15', 'xmeas_16', 'xmeas_17', \n",
    "                'xmeas_18', 'xmeas_19', 'xmeas_20', 'xmeas_21', 'xmeas_22', 'xmeas_23', 'xmeas_24', 'xmeas_25', \n",
    "                'xmeas_26', 'xmeas_27', 'xmeas_28', 'xmeas_29', 'xmeas_30', 'xmeas_31', 'xmeas_32', 'xmeas_33', \n",
    "                'xmeas_34', 'xmeas_35', 'xmeas_36', 'xmeas_37', 'xmeas_38', 'xmeas_39', 'xmeas_40', 'xmeas_41', \n",
    "                'xmv_1', 'xmv_2', 'xmv_3', 'xmv_4', 'xmv_5', 'xmv_6', 'xmv_7', 'xmv_8', 'xmv_9', 'xmv_10', 'xmv_11'\n",
    "            ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.index.nunique()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        features = self.X.loc[idx][self.features].values[160 : (161+self.seq_length), :]\n",
    "        target = self.X.loc[idx]['faultNumber'].unique()[0]\n",
    "\n",
    "        features = torch.tensor(features, dtype=torch.float)\n",
    "        target = torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "        return features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "SEQ_LENGTH = [1, 5, 10, 25, 50, 100, 200, 250, 300]\n",
    "metrics = dict()\n",
    "y_ans_test_all = []\n",
    "\n",
    "for seq_length in SEQ_LENGTH:\n",
    "    \n",
    "    y_ans_test, y_true_test = [], []\n",
    "    \n",
    "    test_ds = DataTEST(raw_test, seq_length=seq_length)\n",
    "    test_dl = DataLoader(test_ds, batch_size=512)\n",
    "\n",
    "    start = time.time()\n",
    "    print(f'seq_length: {seq_length}\\n')\n",
    "\n",
    "    model.eval()\n",
    "    for (X_batch_test, y_batch_test) in tqdm(test_dl):\n",
    "        \n",
    "        print(X_batch_test.size())\n",
    "        \n",
    "        X_batch_lengths_test = torch.tensor([seq_length]*len(X_batch_test)).to(device)\n",
    "\n",
    "        X_batch_test, y_batch_test = X_batch_test.to(device), y_batch_test.to(device)\n",
    "\n",
    "        y_pred_test = model(X_batch_test, X_batch_lengths_test)\n",
    "\n",
    "        y_pred_prob = F.softmax(y_pred_test.cpu(), dim=-1)\n",
    "        y_pred_class = y_pred_prob.max(dim=-1)[1]\n",
    "       \n",
    "        y_ans_test += y_pred_class.tolist()\n",
    "        y_true_test += y_batch_test.tolist()\n",
    "        \n",
    "        end = time.time()\n",
    "        \n",
    "    y_ans_test_all.append(y_ans_test)\n",
    "        \n",
    "    TPR, FPR, ACCURACY = get_metrics(y_true_test, y_ans_test)\n",
    "    \n",
    "#     print(\"Classes True\", round(pd.Series(y_true_test).value_counts(normalize=True).sort_index(), 4).to_dict())\n",
    "#     print(\"Classes False\", round(pd.Series(y_ans_test).value_counts(normalize=True).sort_index(), 4).to_dict())\n",
    "    \n",
    "#     print(\"TPR\", np.round(TPR, 4))\n",
    "#     print(\"FPR\", np.round(FPR, 4))\n",
    "#     print(\"ACCURACY\", np.round(ACCURACY, 4))\n",
    "    \n",
    "    metrics[seq_length] = [TPR, FPR, ACCURACY]\n",
    "    \n",
    "    print(f\"seq_length time: {end - start}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ans_test_all = np.array(y_ans_test_all).T\n",
    "y_true_test_all = np.array(y_true_test).T\n",
    "\n",
    "y_ans_test_all.shape, y_true_test_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_delay = get_detection_delay(y_true=y_true_test_all, y_pred=y_ans_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting(metrics[seq_length][0], \"TPR\")\n",
    "plotting(metrics[seq_length][1], \"FPR\")\n",
    "plotting(metrics[seq_length][2], \"ACCURACY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_delay_mean = {}\n",
    "for (k, v) in detection_delay.items():\n",
    "    detection_delay_mean[k] = np.nanmean(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_delay_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(list(detection_delay_mean.values())), '-go')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwinModel(torch.nn.Module) :\n",
    "    def __init__(self, NUM_LAYERS, INPUT_SIZE, HIDDEN_SIZE, LINEAR_SIZE, OUTPUT_SIZE, BIDIRECTIONAL, DEVICE):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = HIDDEN_SIZE\n",
    "        self.num_layers = NUM_LAYERS\n",
    "        self.input_size = INPUT_SIZE\n",
    "        self.linear_size = LINEAR_SIZE\n",
    "        self.output_size = OUTPUT_SIZE\n",
    "        self.bidirectional = BIDIRECTIONAL\n",
    "        \n",
    "        self.lstm_1 = nn.LSTM(\n",
    "                        input_size=self.input_size[0], \n",
    "                        hidden_size=self.hidden_size,\n",
    "                        num_layers=self.num_layers, \n",
    "                        bidirectional=self.bidirectional,\n",
    "                        batch_first=True,\n",
    "                        dropout=0.4\n",
    "            )\n",
    "        \n",
    "        self.lstm_2 = nn.LSTM(\n",
    "                        input_size=self.input_size[1],\n",
    "                        hidden_size=self.hidden_size,\n",
    "                        num_layers=self.num_layers, \n",
    "                        bidirectional=self.bidirectional,\n",
    "                        batch_first=True,\n",
    "                        dropout=0.4\n",
    "            )\n",
    "        \n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "                        nn.Linear(in_features=2*self.hidden_size*(self.bidirectional+1), out_features=self.linear_size),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(p=0.4),\n",
    "                        nn.Linear(in_features=self.linear_size, out_features=OUTPUT_SIZE),\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x_1 = x[:, :, :41]\n",
    "        x_2 = x[:, :, 41:]\n",
    "        \n",
    "        x_1, _ = self.lstm_1(x_1)\n",
    "        x_2, __ = self.lstm_2(x_2)\n",
    "        \n",
    "        x_3 = torch.cat((x_1[:, -1], x_2[:, -1]), dim=-1)\n",
    "        \n",
    "        x = self.head(x_3)\n",
    "        \n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
